{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4d9f7ed-d413-407b-bc72-b4b1bf02ef77",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e642414e-0b0c-41ec-88a2-590d1b82a4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "def prepare_data(file='ready_file_for_ML_April.csv'):\n",
    "    \"\"\"\n",
    "    Prepares the dataset for machine learning analysis by filtering relevant data, applying one-hot encoding,\n",
    "    computing differential conditions, and removing genes with no significant changes.\n",
    "\n",
    "    Parameters:\n",
    "    file (str): Path to the CSV file containing the initial data.\n",
    "\n",
    "    Returns:\n",
    "    tuple: A tuple containing two pandas DataFrames, each filtered by different conditions.\n",
    "    \"\"\"\n",
    "    # Loading the dataset and excluding specified columns to focus on relevant data\n",
    "    df = pd.read_csv(file)\n",
    "    exclude_columns = ['Geneid', 'shScramble', 'shDDX41', 'DMSO', 'CX5461']\n",
    "    # Filtering rows where at least one column has a non-zero value\n",
    "    rows_at_least_one_nonzero = df.drop(columns=exclude_columns).any(axis=1)\n",
    "    result = df[rows_at_least_one_nonzero]\n",
    "    \n",
    "    # Applying one-hot encoding to the 'Geneid' column to turn categorical gene IDs into binary features\n",
    "    one_hot_encoded_df = pd.get_dummies(result, columns=['Geneid'], dtype=int)\n",
    "    \n",
    "    # Calculating conditions by finding the differences between treatments and controls\n",
    "    one_hot_encoded_df['condition1'] = one_hot_encoded_df['shScramble'] - one_hot_encoded_df['shDDX41']\n",
    "    one_hot_encoded_df['condition2'] = one_hot_encoded_df['DMSO'] - one_hot_encoded_df['CX5461']\n",
    "    \n",
    "    # Applying the sign function to set negative differences to -1, zero to 0, and positive to +1\n",
    "    one_hot_encoded_df['condition1'] = np.sign(one_hot_encoded_df['condition1'])\n",
    "    one_hot_encoded_df['condition2'] = np.sign(one_hot_encoded_df['condition2'])\n",
    "    \n",
    "    # List of columns to be removed\n",
    "    columns_to_remove =  ['shScramble', 'shDDX41', 'DMSO', 'CX5461']\n",
    "    \n",
    "    # Removing the specified columns\n",
    "    one_hot_encoded_df.drop(columns=columns_to_remove, inplace=True)\n",
    "\n",
    "    # Separating datasets for each condition and exclude rows without significant change (value 0)\n",
    "    df1 = one_hot_encoded_df.drop(columns=['condition2'])\n",
    "    df2 = one_hot_encoded_df.drop(columns=['condition1'])\n",
    "    #df1 = df1[df1['condition1'] != 0]\n",
    "    #df2 = df2[df2['condition2'] != 0]\n",
    "\n",
    "    return df1, df2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d711c3d5-b57a-4ba3-b533-dd036a64fca1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cab88ac7-940e-4bec-a790-79db36b2076d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report \n",
    "\n",
    "def model_data(df, target, model, param_dist, n_class=2, convert_to_binary=False, n_iter=2, actual_value = False): \n",
    "    \"\"\"\n",
    "    Fit and evaluate a machine learning model on the provided dataset.\n",
    "\n",
    "    Parameters:\n",
    "    - df: DataFrame with features and target.\n",
    "    - target: Name of the target column.\n",
    "    - model: ML model to be trained.\n",
    "    - param_dist: Hyperparameter distribution for tuning.\n",
    "    - n_class: Number of classes (default 2).\n",
    "    - convert_to_binary: Convert non-binary targets to binary (default False).\n",
    "    - n_iter: Iterations for parameter tuning (default 2).\n",
    "    - actual_value: Use actual feature values (default False).\n",
    "    \n",
    "    Outputs:\n",
    "    - Model accuracy and classification report.\n",
    "    - Best parameters if tuned.\n",
    "    \"\"\"\n",
    "    print(\"*********************************************************\")\n",
    "    print(\"Running the model task with the following parameters:\")\n",
    "    print(\"target:\", target)\n",
    "    print(\"model:\", model)\n",
    "\n",
    "    for param, dist in param_dist.items():\n",
    "        if type(dist) is list:\n",
    "            sampled_values = dist\n",
    "        else:\n",
    "            sampled_values = dist.rvs(n_iter)\n",
    "        print(f\"{param}: {sampled_values}\")\n",
    "    print(\"n_class:\", n_class)\n",
    "    print(\"n_iter:\", n_iter)\n",
    "    print(\"actual_value:\", actual_value, \"\\n\\n\")\n",
    "\n",
    "    # Re-encoding the target: 0 -> 0, 1 -> 1, -1 -> 2\n",
    "    if n_class == 2:\n",
    "        df[target] = df[target].replace({-1: 0})\n",
    "    else: \n",
    "        df[target] = df[target].replace({-1: 2})\n",
    "\n",
    "    # Separating features and the target\n",
    "    X = df.drop(target, axis=1)\n",
    "    y = df[target]    \n",
    "    # Function to convert positive numbers to 1 and negative numbers to 0\n",
    "    if actual_value == False:\n",
    "        if convert_to_binary:\n",
    "            convert_function = lambda x: 1 if x > 0 else 0\n",
    "            X = X.applymap(convert_function)\n",
    "    else:\n",
    "        X = X.round(2)\n",
    "\n",
    "    # Splitting the dataset into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    if n_iter > 1:\n",
    "        # Hyperparameter optimization using RandomizedSearchCV\n",
    "        randomized_search = RandomizedSearchCV(model, param_distributions=param_dist, n_iter=n_iter, scoring='accuracy', cv=3, verbose=1, random_state=42)\n",
    "        # Training the model with the best parameters\n",
    "        randomized_search.fit(X_train, y_train)\n",
    "        # Best model\n",
    "        best_model = randomized_search.best_estimator_\n",
    "    else:\n",
    "        # Training the model with default parameters\n",
    "        model.fit(X_train, y_train)\n",
    "        best_model = model\n",
    "    # Predicting\n",
    "    predictions = best_model.predict(X_test)   \n",
    "    if  n_class ==2:\n",
    "        predictions = [1 if prob > 0.5 else 0 for prob in predictions]\n",
    "\n",
    "    # Evaluation\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"\\nClassification Report:\\n\", classification_report(y_test, predictions))\n",
    "\n",
    "    if n_iter > 1:\n",
    "        print(\"\\nBest Parameters:\\n\", randomized_search.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "213165a4-7427-4f45-8e44-b96ca44874fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report \n",
    "\n",
    "def model_data(df, target, model, param_dist, n_class=2, convert_to_binary=False, n_iter=2, actual_value = False): \n",
    "    \"\"\"\n",
    "    Fit and evaluate a machine learning model on the provided dataset.\n",
    "\n",
    "    Parameters:\n",
    "    - df: DataFrame with features and target.\n",
    "    - target: Name of the target column.\n",
    "    - model: ML model to be trained.\n",
    "    - param_dist: Hyperparameter distribution for tuning.\n",
    "    - n_class: Number of classes (default 2).\n",
    "    - convert_to_binary: Convert non-binary targets to binary (default False).\n",
    "    - n_iter: Iterations for parameter tuning (default 2).\n",
    "    - actual_value: Use actual feature values (default False).\n",
    "    \n",
    "    Outputs:\n",
    "    - Model accuracy and classification report.\n",
    "    - Best parameters if tuned.\n",
    "    \"\"\"\n",
    "    print(\"*********************************************************\")\n",
    "    print(\"Running the model task with the following parameters:\")\n",
    "    print(\"target:\", target)\n",
    "    print(\"model:\", model)\n",
    "\n",
    "    for param, dist in param_dist.items():\n",
    "        if type(dist) is list:\n",
    "            sampled_values = dist\n",
    "        else:\n",
    "            sampled_values = dist.rvs(n_iter)\n",
    "        print(f\"{param}: {sampled_values}\")\n",
    "    print(\"n_class:\", n_class)\n",
    "    print(\"n_iter:\", n_iter)\n",
    "    print(\"actual_value:\", actual_value, \"\\n\\n\")\n",
    "\n",
    "    # Re-encoding the target: 0 -> 0, 1 -> 1, -1 -> 2\n",
    "    if n_class == 2:\n",
    "        df[target] = df[target].replace({-1: 0})\n",
    "    else: \n",
    "        df[target] = df[target].replace({-1: 2})\n",
    "\n",
    "    # Separating features and the target\n",
    "    X = df.drop(target, axis=1)\n",
    "    y = df[target]    \n",
    "    # Function to convert positive numbers to 1 and negative numbers to 0\n",
    "    if actual_value == False:\n",
    "        if convert_to_binary:\n",
    "            convert_function = lambda x: 1 if x > 0 else 0\n",
    "            X = X.applymap(convert_function)\n",
    "    else:\n",
    "        X = X.round(2)\n",
    "\n",
    "    # Splitting the dataset into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    if n_iter > 1:\n",
    "        # Hyperparameter optimization using RandomizedSearchCV\n",
    "        randomized_search = RandomizedSearchCV(model, param_distributions=param_dist, n_iter=n_iter, scoring='accuracy', cv=3, verbose=1, random_state=42)\n",
    "        # Training the model with the best parameters\n",
    "        randomized_search.fit(X_train, y_train)\n",
    "        # Best model\n",
    "        best_model = randomized_search.best_estimator_\n",
    "    else:\n",
    "        # Training the model with default parameters\n",
    "        model.fit(X_train, y_train)\n",
    "        best_model = model\n",
    "    # Predicting\n",
    "    predictions = best_model.predict(X_test)   \n",
    "    if  n_class ==2:\n",
    "        predictions = [1 if prob > 0.5 else 0 for prob in predictions]\n",
    "\n",
    "    # Evaluation\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"\\nClassification Report:\\n\", classification_report(y_test, predictions))\n",
    "\n",
    "    if n_iter > 1:\n",
    "        print(\"\\nBest Parameters:\\n\", randomized_search.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "69e045fb-4d6c-4573-8449-a6ad3d520f96",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from scipy.stats import randint, uniform\n",
    "\n",
    "# Example parameter grids for different models\n",
    "param_grid_xgb = {\n",
    "    'max_depth': randint(3, 10),\n",
    "    'learning_rate': uniform(0.01, 0.3),\n",
    "    'n_estimators': randint(50, 200),\n",
    "    'subsample': uniform(0.6, 0.4),\n",
    "    'colsample_bytree': uniform(0.5, 0.5),\n",
    "    'gamma': uniform(0, 0.5)\n",
    "}\n",
    "\n",
    "param_grid_rf = {\n",
    "    'n_estimators': randint(50, 200),\n",
    "    'max_depth': randint(3, 10),\n",
    "    'min_samples_split': randint(2, 10),\n",
    "    'min_samples_leaf': randint(1, 10)\n",
    "}\n",
    "\n",
    "param_grid_ab = {\n",
    "    'n_estimators': randint(50, 200),\n",
    "    'learning_rate': uniform(0.01, 1)\n",
    "}\n",
    "\n",
    "param_grid_sgd = {\n",
    "    'alpha': [0.0001, 0.001, 0.01, 0.1],\n",
    "    'max_iter': randint(1000, 10000),\n",
    "    'tol': [1e-3],\n",
    "    'penalty': ['l2', 'l1', 'elasticnet']\n",
    "}\n",
    "\n",
    "param_grid_knn = {\n",
    "    'n_neighbors': randint(3, 30),\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'algorithm': ['ball_tree', 'kd_tree', 'brute']\n",
    "}\n",
    "\n",
    "param_grid_nb = {}  # Naive Bayes usually does not require hyperparameter tuning\n",
    "\n",
    "# Example usage\n",
    "#model_data(your_dataframe, 'target_column_name', RandomForestClassifier(), param_grid_rf)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4fd3b30d-d561-4b87-a717-cde8d8fbcdde",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1, df2 = prepare_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22ee55c-d1df-453d-ba0c-ab4887b838b3",
   "metadata": {},
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e400b05e-d829-4ce0-9fd6-40cf06dec321",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DDX1</th>\n",
       "      <th>XRCC6</th>\n",
       "      <th>GEMIN5</th>\n",
       "      <th>DROSHA</th>\n",
       "      <th>HNRNPUL1</th>\n",
       "      <th>FTO</th>\n",
       "      <th>MORC2</th>\n",
       "      <th>SSB</th>\n",
       "      <th>U2AF2</th>\n",
       "      <th>CSTF2T</th>\n",
       "      <th>...</th>\n",
       "      <th>Geneid_ENSG00000290315.1</th>\n",
       "      <th>Geneid_ENSG00000290318.1</th>\n",
       "      <th>Geneid_ENSG00000291237.1</th>\n",
       "      <th>Geneid_ENSG00000291307.1</th>\n",
       "      <th>Geneid_ENSG00000291313.1</th>\n",
       "      <th>Geneid_ENSG00000291316.1</th>\n",
       "      <th>Geneid_ENSG00000291317.1</th>\n",
       "      <th>Geneid_ENSG00000293552.1</th>\n",
       "      <th>Geneid_ENSG00000293553.1</th>\n",
       "      <th>condition1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3.744698</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.401821</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20044</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20045</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20046</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20047</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20048</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9521 rows Ã— 9661 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           DDX1  XRCC6  GEMIN5  DROSHA  HNRNPUL1  FTO     MORC2  SSB  U2AF2  \\\n",
       "4      0.000000    0.0     0.0     0.0       0.0  0.0  0.000000  0.0    0.0   \n",
       "5      0.000000    0.0     0.0     0.0       0.0  0.0  0.000000  0.0    0.0   \n",
       "8      0.000000    0.0     0.0     0.0       0.0  0.0  0.000000  0.0    0.0   \n",
       "9      0.000000    0.0     0.0     0.0       0.0  0.0  0.000000  0.0    0.0   \n",
       "10     3.744698    0.0     0.0     0.0       0.0  0.0  3.401821  0.0    0.0   \n",
       "...         ...    ...     ...     ...       ...  ...       ...  ...    ...   \n",
       "20044  0.000000    0.0     0.0     0.0       0.0  0.0  0.000000  0.0    0.0   \n",
       "20045  0.000000    0.0     0.0     0.0       0.0  0.0  0.000000  0.0    0.0   \n",
       "20046  0.000000    0.0     0.0     0.0       0.0  0.0  0.000000  0.0    0.0   \n",
       "20047  0.000000    0.0     0.0     0.0       0.0  0.0  0.000000  0.0    0.0   \n",
       "20048  0.000000    0.0     0.0     0.0       0.0  0.0  0.000000  0.0    0.0   \n",
       "\n",
       "       CSTF2T  ...  Geneid_ENSG00000290315.1  Geneid_ENSG00000290318.1  \\\n",
       "4         0.0  ...                         0                         0   \n",
       "5         0.0  ...                         0                         0   \n",
       "8         0.0  ...                         0                         0   \n",
       "9         0.0  ...                         0                         0   \n",
       "10        0.0  ...                         0                         0   \n",
       "...       ...  ...                       ...                       ...   \n",
       "20044     0.0  ...                         0                         0   \n",
       "20045     0.0  ...                         0                         0   \n",
       "20046     0.0  ...                         0                         0   \n",
       "20047     0.0  ...                         0                         0   \n",
       "20048     0.0  ...                         0                         0   \n",
       "\n",
       "       Geneid_ENSG00000291237.1  Geneid_ENSG00000291307.1  \\\n",
       "4                             0                         0   \n",
       "5                             0                         0   \n",
       "8                             0                         0   \n",
       "9                             0                         0   \n",
       "10                            0                         0   \n",
       "...                         ...                       ...   \n",
       "20044                         0                         0   \n",
       "20045                         0                         0   \n",
       "20046                         0                         0   \n",
       "20047                         0                         0   \n",
       "20048                         0                         0   \n",
       "\n",
       "       Geneid_ENSG00000291313.1  Geneid_ENSG00000291316.1  \\\n",
       "4                             0                         0   \n",
       "5                             0                         0   \n",
       "8                             0                         0   \n",
       "9                             0                         0   \n",
       "10                            0                         0   \n",
       "...                         ...                       ...   \n",
       "20044                         0                         0   \n",
       "20045                         0                         0   \n",
       "20046                         0                         0   \n",
       "20047                         0                         0   \n",
       "20048                         0                         0   \n",
       "\n",
       "       Geneid_ENSG00000291317.1  Geneid_ENSG00000293552.1  \\\n",
       "4                             0                         0   \n",
       "5                             0                         0   \n",
       "8                             0                         0   \n",
       "9                             0                         0   \n",
       "10                            0                         0   \n",
       "...                         ...                       ...   \n",
       "20044                         0                         0   \n",
       "20045                         0                         0   \n",
       "20046                         0                         0   \n",
       "20047                         0                         0   \n",
       "20048                         0                         0   \n",
       "\n",
       "       Geneid_ENSG00000293553.1  condition1  \n",
       "4                             0        -1.0  \n",
       "5                             0        -1.0  \n",
       "8                             0         1.0  \n",
       "9                             0        -1.0  \n",
       "10                            0         1.0  \n",
       "...                         ...         ...  \n",
       "20044                         0         0.0  \n",
       "20045                         0         0.0  \n",
       "20046                         0         0.0  \n",
       "20047                         0         0.0  \n",
       "20048                         0         0.0  \n",
       "\n",
       "[9521 rows x 9661 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89779b89-fa1b-46dd-ac08-a8ee4dc6c29c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Actual Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98dd2cf-f302-4bad-99e1-29b26dc71dfd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************************************************\n",
      "Running the model task with the following parameters:\n",
      "target: condition1\n",
      "model: XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...)\n",
      "max_depth: [5 3 3 8 9 7 9 7 3 3]\n",
      "learning_rate: [0.10131738 0.03262122 0.25762722 0.12869784 0.01431766 0.10929475\n",
      " 0.26354735 0.23860774 0.3049014  0.18821917]\n",
      "n_estimators: [105 170 187 191 126 177 176  69  65  68]\n",
      "subsample: [0.6914838  0.97484868 0.99995565 0.68161751 0.97639601 0.6992176\n",
      " 0.83753038 0.65864603 0.65141641 0.70102154]\n",
      "colsample_bytree: [0.50611238 0.88437868 0.87813022 0.7691559  0.66633898 0.55365642\n",
      " 0.60178734 0.76854069 0.58398145 0.61103187]\n",
      "gamma: [0.26178817 0.3182612  0.03608319 0.17978367 0.40117122 0.23361155\n",
      " 0.46047616 0.31177481 0.35867105 0.30208862]\n",
      "n_class: 2\n",
      "n_iter: 10\n",
      "actual_value: True \n",
      "\n",
      "\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Accuracy: 0.6047244094488189\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.61      0.78      0.69      1051\n",
      "         1.0       0.59      0.39      0.47       854\n",
      "\n",
      "    accuracy                           0.60      1905\n",
      "   macro avg       0.60      0.58      0.58      1905\n",
      "weighted avg       0.60      0.60      0.59      1905\n",
      "\n",
      "\n",
      "Best Parameters:\n",
      " {'colsample_bytree': 0.5066324805799333, 'gamma': 0.4711008778424264, 'learning_rate': 0.17898646535366178, 'max_depth': 4, 'n_estimators': 58, 'subsample': 0.6063865008880857}\n",
      "*********************************************************\n",
      "Running the model task with the following parameters:\n",
      "target: condition1\n",
      "model: RandomForestClassifier()\n",
      "n_estimators: [199 141  53 104 181 122 173 139 130  57]\n",
      "max_depth: [9 9 6 8 3 5 3 3 9 5]\n",
      "min_samples_split: [6 8 3 2 9 9 9 6 7 9]\n",
      "min_samples_leaf: [7 4 4 7 8 3 4 5 8 3]\n",
      "n_class: 2\n",
      "n_iter: 10\n",
      "actual_value: True \n",
      "\n",
      "\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Accuracy: 0.5627296587926509\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.56      0.99      0.71      1051\n",
      "         1.0       0.74      0.04      0.07       854\n",
      "\n",
      "    accuracy                           0.56      1905\n",
      "   macro avg       0.65      0.51      0.39      1905\n",
      "weighted avg       0.64      0.56      0.43      1905\n",
      "\n",
      "\n",
      "Best Parameters:\n",
      " {'max_depth': 9, 'min_samples_leaf': 5, 'min_samples_split': 2, 'n_estimators': 67}\n",
      "*********************************************************\n",
      "Running the model task with the following parameters:\n",
      "target: condition1\n",
      "model: AdaBoostClassifier()\n",
      "n_estimators: [147 170  51 100 191  77 101 141 147  91]\n",
      "learning_rate: [0.20225527 0.11461013 0.19549619 0.20675901 0.78395809 0.56192609\n",
      " 0.90594486 0.20338635 0.40390158 0.60008322]\n",
      "n_class: 2\n",
      "n_iter: 10\n",
      "actual_value: True \n",
      "\n",
      "\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Accuracy: 0.610498687664042\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.61      0.83      0.70      1051\n",
      "         1.0       0.62      0.34      0.44       854\n",
      "\n",
      "    accuracy                           0.61      1905\n",
      "   macro avg       0.61      0.58      0.57      1905\n",
      "weighted avg       0.61      0.61      0.58      1905\n",
      "\n",
      "\n",
      "Best Parameters:\n",
      " {'learning_rate': 0.1934347898661638, 'n_estimators': 121}\n",
      "*********************************************************\n",
      "Running the model task with the following parameters:\n",
      "target: condition1\n",
      "model: SGDClassifier()\n",
      "alpha: [0.0001, 0.001, 0.01, 0.1]\n",
      "max_iter: [1186 9512 2311 8048 9184 8922 3745 5386 3188 9204]\n",
      "tol: [0.001]\n",
      "penalty: ['l2', 'l1', 'elasticnet']\n",
      "n_class: 2\n",
      "n_iter: 10\n",
      "actual_value: True \n",
      "\n",
      "\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Accuracy: 0.5763779527559055\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.57      0.95      0.71      1051\n",
      "         1.0       0.66      0.12      0.20       854\n",
      "\n",
      "    accuracy                           0.58      1905\n",
      "   macro avg       0.61      0.53      0.45      1905\n",
      "weighted avg       0.61      0.58      0.48      1905\n",
      "\n",
      "\n",
      "Best Parameters:\n",
      " {'alpha': 0.1, 'max_iter': 9322, 'penalty': 'l1', 'tol': 0.001}\n",
      "*********************************************************\n",
      "Running the model task with the following parameters:\n",
      "target: condition1\n",
      "model: KNeighborsClassifier()\n",
      "n_neighbors: [ 8 23 28  5  5 24 13 19 26  5]\n",
      "weights: ['uniform', 'distance']\n",
      "algorithm: ['ball_tree', 'kd_tree', 'brute']\n",
      "n_class: 2\n",
      "n_iter: 10\n",
      "actual_value: True \n",
      "\n",
      "\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    }
   ],
   "source": [
    "model_data(df=df1, target='condition1', model = xgb.XGBClassifier(), param_dist= param_grid_xgb,\n",
    "           n_iter=10, actual_value= True)\n",
    "model_data(df=df1, target='condition1', model = RandomForestClassifier(), param_dist= param_grid_rf,\n",
    "           n_iter=10, actual_value= True)\n",
    "model_data(df=df1, target='condition1', model = AdaBoostClassifier(), param_dist= param_grid_ab,\n",
    "           n_iter=10, actual_value= True)\n",
    "\n",
    "model_data(df=df1, target='condition1', model = SGDClassifier(), param_dist= param_grid_sgd,\n",
    "           n_iter=10, actual_value= True)\n",
    "\n",
    "model_data(df=df1, target='condition1', model = KNeighborsClassifier(), param_dist= param_grid_knn,\n",
    "           n_iter=10, actual_value= True)\n",
    "\n",
    "model_data(df=df1, target='condition1', model = GaussianNB(), param_dist= param_grid_nb,\n",
    "           n_iter=10, actual_value= True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "548a30c1-8e48-4653-9469-2136f93a4d9c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************************************************\n",
      "Running the model task with the following parameters:\n",
      "target: condition1\n",
      "model: KNeighborsClassifier()\n",
      "n_neighbors: [ 9 14 12 13 23 26 22 22 24 18]\n",
      "weights: ['uniform', 'distance']\n",
      "algorithm: ['ball_tree', 'kd_tree', 'brute']\n",
      "n_class: 2\n",
      "n_iter: 10\n",
      "actual_value: True \n",
      "\n",
      "\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Accuracy: 0.579002624671916\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.59      0.75      0.66      1051\n",
      "         1.0       0.54      0.37      0.44       854\n",
      "\n",
      "    accuracy                           0.58      1905\n",
      "   macro avg       0.57      0.56      0.55      1905\n",
      "weighted avg       0.57      0.58      0.56      1905\n",
      "\n",
      "\n",
      "Best Parameters:\n",
      " {'algorithm': 'ball_tree', 'n_neighbors': 23, 'weights': 'uniform'}\n",
      "*********************************************************\n",
      "Running the model task with the following parameters:\n",
      "target: condition1\n",
      "model: GaussianNB()\n",
      "n_class: 2\n",
      "n_iter: 10\n",
      "actual_value: True \n",
      "\n",
      "\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Accuracy: 0.44881889763779526\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.67      0.00      0.00      1051\n",
      "         1.0       0.45      1.00      0.62       854\n",
      "\n",
      "    accuracy                           0.45      1905\n",
      "   macro avg       0.56      0.50      0.31      1905\n",
      "weighted avg       0.57      0.45      0.28      1905\n",
      "\n",
      "\n",
      "Best Parameters:\n",
      " {}\n"
     ]
    }
   ],
   "source": [
    "model_data(df=df1, target='condition1', model = KNeighborsClassifier(), param_dist= param_grid_knn,\n",
    "           n_iter=10, actual_value= True)\n",
    "\n",
    "model_data(df=df1, target='condition1', model = GaussianNB(), param_dist= param_grid_nb,\n",
    "           n_iter=10, actual_value= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179b703d-2bd3-441d-818e-78bbd059de74",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************************************************\n",
      "Running the model task with the following parameters:\n",
      "target: condition1\n",
      "model: XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...)\n",
      "max_depth: [6 3 4 3 5 3 9 7 9 9 9 5 7 8 7 4 8 8 4 7 9 8 6 5 9 6 3 4 7 7 8 5 5 3 3 6 4\n",
      " 7 4 8 8 9 8 7 5 5 8 6 6 7 9 5 6 6 9 4 3 3 8 7 9 9 4 3 6 3 4 3 5 6 6 5 6 9\n",
      " 8 9 7 8 3 4 7 5 7 8 5 6 4 8 8 8 4 8 8 8 7 3 4 4 9 8]\n",
      "learning_rate: [0.01795742 0.0727156  0.28160083 0.28649336 0.29913796 0.29438061\n",
      " 0.05961809 0.04550473 0.10080838 0.15688168 0.13513722 0.12308175\n",
      " 0.1793409  0.13872303 0.22414494 0.153334   0.05417763 0.224075\n",
      " 0.19038659 0.03135524 0.20244164 0.03516694 0.12707193 0.29647417\n",
      " 0.12282771 0.17771688 0.28817525 0.21376838 0.14575114 0.24995627\n",
      " 0.26926365 0.22537127 0.03732575 0.25912003 0.24329113 0.02790212\n",
      " 0.14362359 0.01432524 0.11795538 0.04213564 0.20983262 0.25727315\n",
      " 0.16865854 0.12930943 0.29618373 0.2645944  0.18211822 0.14186573\n",
      " 0.01721624 0.23401718 0.24436867 0.14655422 0.03216938 0.22251182\n",
      " 0.03083616 0.13167089 0.20883897 0.16842241 0.19541097 0.27328875\n",
      " 0.08695868 0.11745686 0.17455408 0.13064821 0.13677485 0.03404568\n",
      " 0.13317943 0.09700224 0.26634758 0.30912221 0.07728117 0.25180554\n",
      " 0.27198652 0.291068   0.12588523 0.29206001 0.11160142 0.2656693\n",
      " 0.01103941 0.24549127 0.29210708 0.13930738 0.23365411 0.30838472\n",
      " 0.16496596 0.05162536 0.22696269 0.16311048 0.23231928 0.18022127\n",
      " 0.01927528 0.03374413 0.12541419 0.26147509 0.14035781 0.30829143\n",
      " 0.18664436 0.26259777 0.15146347 0.11162793]\n",
      "n_estimators: [131 106 179 125 182  84  92 140  55 181 194  95  52 115 166 168  95  93\n",
      " 185 182 121  94 115 140 138  64  54  52 182 135 143 162 189 166  58 126\n",
      " 198 110 188 149  80 143 164 165 135 178 108 163  97  89  54 120 141  67\n",
      " 179 159  95 139  91 151  89 188 124  90  95 117 142  51 129 135  56 137\n",
      "  93  71  90 119 184 124 131 174  68 155 181 176 148  77 139  57 167 181\n",
      "  91  88 123 107  51 155 142 168 154 172]\n",
      "subsample: [0.71930632 0.6277921  0.99866927 0.61196191 0.61421707 0.86221931\n",
      " 0.64563317 0.61443038 0.68118066 0.84792954 0.98267964 0.78592257\n",
      " 0.72913252 0.8419476  0.93912725 0.72031838 0.72553961 0.8537327\n",
      " 0.89485065 0.72794486 0.9781287  0.9408873  0.78380945 0.98272569\n",
      " 0.88521501 0.84032738 0.99530921 0.84238917 0.79647732 0.82266903\n",
      " 0.77269766 0.78218998 0.68868421 0.88322141 0.86426386 0.93057607\n",
      " 0.8463927  0.66895933 0.79808565 0.80708295 0.68003337 0.77439956\n",
      " 0.65835764 0.71651146 0.95243217 0.69206297 0.96168949 0.74380346\n",
      " 0.94856746 0.62148622 0.6484764  0.98212481 0.85966133 0.64727907\n",
      " 0.90807831 0.80320088 0.73519209 0.62795129 0.6110557  0.93913977\n",
      " 0.63695241 0.62871282 0.86367589 0.61889993 0.81439712 0.70982294\n",
      " 0.66024769 0.70601809 0.96917448 0.76791867 0.79671672 0.72343789\n",
      " 0.78115706 0.72749119 0.65486789 0.62874325 0.70823396 0.852569\n",
      " 0.6623621  0.83538344 0.87016415 0.70092398 0.64350232 0.60478956\n",
      " 0.64575097 0.85979138 0.73864927 0.80043634 0.62242377 0.7255524\n",
      " 0.91087202 0.73578017 0.77522797 0.91268411 0.89888555 0.79934433\n",
      " 0.87099997 0.69860147 0.6251372  0.90470056]\n",
      "colsample_bytree: [0.7114188  0.71367132 0.99166387 0.97797133 0.74345961 0.6218305\n",
      " 0.61156375 0.78408371 0.63160722 0.91061365 0.74604126 0.77074069\n",
      " 0.67652274 0.73271907 0.7366159  0.8755522  0.96034818 0.95436174\n",
      " 0.74824181 0.71175691 0.53617979 0.92214123 0.79997746 0.54850261\n",
      " 0.91148125 0.51022612 0.64216881 0.73919547 0.82807676 0.97590417\n",
      " 0.80415865 0.91923601 0.71043004 0.8599117  0.78683482 0.97254657\n",
      " 0.58046576 0.54607645 0.9123702  0.91649023 0.57948123 0.98677598\n",
      " 0.84385661 0.51904379 0.84227007 0.72761425 0.91042514 0.95964233\n",
      " 0.8477714  0.5416717  0.5744577  0.75940477 0.54789625 0.81610223\n",
      " 0.71376487 0.76565191 0.66060702 0.60642062 0.96750514 0.82947843\n",
      " 0.75845956 0.72257994 0.86778187 0.56457376 0.50500574 0.67105257\n",
      " 0.83600569 0.89243723 0.50054814 0.63298784 0.95890143 0.53538405\n",
      " 0.70983929 0.80239935 0.83075236 0.825058   0.75689565 0.87972443\n",
      " 0.85000125 0.755761   0.98517698 0.75577618 0.62786925 0.9823793\n",
      " 0.52535027 0.68700042 0.65132446 0.66247024 0.92949093 0.673286\n",
      " 0.94859102 0.86103933 0.65678485 0.60015554 0.87402248 0.76478247\n",
      " 0.76552309 0.78145945 0.83714078 0.64104456]\n",
      "gamma: [0.27027229 0.10840425 0.49602119 0.28185337 0.3854563  0.4940091\n",
      " 0.22168086 0.21332084 0.28726339 0.47079072 0.35836754 0.25647116\n",
      " 0.15977482 0.14701525 0.43274414 0.21550796 0.32784952 0.11037739\n",
      " 0.19405938 0.00353176 0.17963464 0.20157203 0.20976676 0.36774719\n",
      " 0.19494945 0.46346426 0.49476027 0.02516958 0.46261748 0.29621352\n",
      " 0.01449602 0.15131219 0.46899664 0.04397369 0.05887797 0.04659375\n",
      " 0.23473069 0.41071888 0.13211179 0.27388802 0.37919968 0.28263398\n",
      " 0.02622496 0.10664776 0.1296392  0.36321042 0.05793761 0.28349867\n",
      " 0.13928473 0.28619151 0.02498057 0.47805209 0.13992093 0.36964988\n",
      " 0.18877153 0.45080379 0.29537063 0.19226753 0.02934219 0.06708536\n",
      " 0.43685152 0.33577504 0.39755757 0.15218875 0.27086054 0.45764385\n",
      " 0.14473664 0.30890298 0.03732671 0.2588556  0.27247759 0.30340131\n",
      " 0.07151199 0.35136358 0.49107798 0.46255363 0.45620584 0.29428625\n",
      " 0.23498362 0.32128074 0.04837385 0.24983069 0.03905325 0.49546707\n",
      " 0.4801895  0.40171307 0.44141341 0.4337131  0.10546144 0.33349299\n",
      " 0.07628539 0.12547503 0.29709141 0.27512259 0.11994602 0.25992633\n",
      " 0.01962485 0.49137442 0.00065729 0.32218305]\n",
      "n_class: 2\n",
      "n_iter: 100\n",
      "actual_value: True \n",
      "\n",
      "\n",
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n",
      "Accuracy: 0.6026246719160105\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.61      0.78      0.68      1051\n",
      "         1.0       0.59      0.39      0.47       854\n",
      "\n",
      "    accuracy                           0.60      1905\n",
      "   macro avg       0.60      0.58      0.58      1905\n",
      "weighted avg       0.60      0.60      0.59      1905\n",
      "\n",
      "\n",
      "Best Parameters:\n",
      " {'colsample_bytree': 0.6079105137484215, 'gamma': 0.31144523790950013, 'learning_rate': 0.0356042394981304, 'max_depth': 7, 'n_estimators': 165, 'subsample': 0.7645415620226714}\n",
      "*********************************************************\n",
      "Running the model task with the following parameters:\n",
      "target: condition1\n",
      "model: RandomForestClassifier()\n",
      "n_estimators: [139 123  53 163 119  80  77  52 173 179 144 181 171 157 197 169 140 137\n",
      "  71 189 109 144 178 188  66 107  78  76  99 121 178 110 140 130 186  51\n",
      " 112  54 116  62 151 136 163 117  65 110  80 166 143  96 139 162  78  73\n",
      " 170  82  71 134 129  91 198 125  88 128  59  84 181 188  97 110 179 164\n",
      " 198  75 123  81 198 199 158 187 127 149 197  69 159  98 168 124  97  96\n",
      "  76 134 102  92 177 111 199  51  61  63]\n",
      "max_depth: [6 6 8 6 8 9 8 3 3 3 4 4 9 7 6 4 9 8 4 3 8 7 6 5 6 3 8 6 3 9 4 5 3 6 6 7 5\n",
      " 5 3 8 3 5 3 6 3 6 6 7 5 7 9 5 9 4 6 5 6 3 8 3 8 8 7 8 3 3 6 4 8 4 7 8 7 7\n",
      " 8 5 5 7 5 9 8 3 8 8 5 9 4 5 6 5 6 7 5 9 5 9 5 4 9 5]\n",
      "min_samples_split: [2 2 7 6 3 6 3 2 2 6 7 2 2 3 5 3 4 3 9 4 2 8 6 4 9 5 6 3 8 7 2 9 3 6 9 9 3\n",
      " 4 2 8 4 4 9 8 6 4 4 4 6 3 3 4 6 9 9 5 4 2 3 6 6 2 7 2 9 2 7 9 3 2 2 9 4 7\n",
      " 7 5 5 6 4 5 9 6 6 8 8 5 9 4 6 2 5 4 6 2 6 9 8 5 3 9]\n",
      "min_samples_leaf: [1 9 7 9 4 3 4 9 8 1 9 9 6 9 5 3 4 1 8 9 3 4 6 6 1 1 1 6 3 3 6 7 1 3 5 6 4\n",
      " 1 9 4 9 7 2 1 2 7 4 4 4 6 1 2 9 4 5 6 3 7 4 1 7 6 5 4 2 5 2 1 2 7 9 7 6 5\n",
      " 2 4 6 8 4 2 4 5 3 9 8 2 5 8 9 6 8 6 2 1 2 6 7 4 4 1]\n",
      "n_class: 2\n",
      "n_iter: 100\n",
      "actual_value: True \n",
      "\n",
      "\n",
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n",
      "Accuracy: 0.5863517060367454\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.58      0.92      0.71      1051\n",
      "         1.0       0.64      0.17      0.27       854\n",
      "\n",
      "    accuracy                           0.59      1905\n",
      "   macro avg       0.61      0.55      0.49      1905\n",
      "weighted avg       0.61      0.59      0.51      1905\n",
      "\n",
      "\n",
      "Best Parameters:\n",
      " {'max_depth': 9, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 145}\n",
      "*********************************************************\n",
      "Running the model task with the following parameters:\n",
      "target: condition1\n",
      "model: AdaBoostClassifier()\n",
      "n_estimators: [122 122 119 195 197  97  70 158 138 192 198  81 146 109 139 194  58  91\n",
      "  88 127 124 114 190  89 126 190  57 178 199  52  65 124 140 155  53 181\n",
      " 138 141  73 189  61 153 120 161 174 136 167 172  63 135 101  70  55 102\n",
      " 187  91  78  94 144 187 135 118 157  50 164  74 159 160 113 190 180 184\n",
      "  71  52 187 199 100 145 188 117  94 191 105 188 135 165  93  86 167 125\n",
      " 176  56  52  58 103  92  86 164 175 123]\n",
      "learning_rate: [0.44477243 0.63444406 0.57542383 0.82440269 0.04715974 0.8135261\n",
      " 0.02935926 0.25931045 0.78465514 0.51981076 0.49289183 0.0405643\n",
      " 0.21057102 0.11417642 0.78000141 0.97290151 0.2371492  0.97265346\n",
      " 0.52534361 0.07213108 0.76344514 0.42318322 0.65037165 0.14376895\n",
      " 0.60997405 0.89972349 0.90584645 0.3528971  0.66345435 0.97188508\n",
      " 0.21642824 0.18104397 0.69620894 0.30546198 0.86107647 0.16630382\n",
      " 1.0068683  0.08852052 0.04906899 0.865077   0.24280373 0.27200727\n",
      " 0.94401594 0.69570687 0.75540173 0.43053849 0.04573297 0.04784952\n",
      " 0.42304647 0.17937241 0.93522405 0.67053973 0.64471573 0.84669784\n",
      " 0.98098216 0.5330592  0.74696795 0.70892333 0.73022993 0.83361113\n",
      " 1.00644462 0.54874958 0.65368402 0.78924222 0.28663876 0.4472315\n",
      " 0.01209783 1.00222158 0.19278588 0.67901402 0.46760217 0.87464919\n",
      " 0.91064395 0.964507   1.00104965 0.8018912  0.59994256 0.42639666\n",
      " 0.6727629  0.9410882  0.99645811 0.44946171 0.15565161 0.39550534\n",
      " 0.69069948 0.24965059 0.60661895 1.00248996 0.6046095  0.70262342\n",
      " 0.70439489 0.95427903 0.51351034 0.15826762 0.32916078 0.27118807\n",
      " 0.78136119 0.64259099 0.90726099 0.59370596]\n",
      "n_class: 2\n",
      "n_iter: 100\n",
      "actual_value: True \n",
      "\n",
      "\n",
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    }
   ],
   "source": [
    "model_data(df=df1, target='condition1', model = xgb.XGBClassifier(), param_dist= param_grid_xgb,\n",
    "           n_iter=100, actual_value= True)\n",
    "model_data(df=df1, target='condition1', model = RandomForestClassifier(), param_dist= param_grid_rf,\n",
    "           n_iter=100, actual_value= True)\n",
    "model_data(df=df1, target='condition1', model = AdaBoostClassifier(), param_dist= param_grid_ab,\n",
    "           n_iter=100, actual_value= True)\n",
    "model_data(df=df1, target='condition1', model = SGDClassifier(), param_dist= param_grid_sgd,\n",
    "           n_iter=100, actual_value= True)\n",
    "\n",
    "model_data(df=df1, target='condition1', model = KNeighborsClassifier(), param_dist= param_grid_knn,\n",
    "           n_iter=100, actual_value= True)\n",
    "\n",
    "model_data(df=df1, target='condition1', model = GaussianNB(), param_dist= param_grid_nb,\n",
    "           n_iter=100, actual_value= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f3bb7931-a635-4a64-90f9-f2b040389ac1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************************************************\n",
      "Running the model task with the following parameters:\n",
      "target: condition1\n",
      "model: AdaBoostClassifier()\n",
      "n_estimators: [196 141  95  82 195 153 110  72 106 133 151  64  65 119 177 105  80 181\n",
      " 150 174  97  65 108 101 138  73  90 179  77 124 107  58 127 114 119  54\n",
      "  80  53 169 140  53  99 144  91  55 138  50  67 182 194 119 125 121 179\n",
      " 159 128 191  87 150  94 133  60 112 184  88 158  50 164  90 190 130  54\n",
      "  73 155  95  60 199 151  74 165  73  87 108 120 120 166  92  66  85 137\n",
      "  63 192 187 108 156  72 124 123  77 138]\n",
      "learning_rate: [0.58706463 0.70621173 0.09709517 0.67997284 0.81852426 0.935102\n",
      " 0.57951902 0.15033405 0.89348993 0.52002428 0.22395024 0.57309572\n",
      " 0.57548008 0.83909905 0.84728036 0.68473517 0.97741898 0.89708361\n",
      " 0.57920961 0.16192169 0.40896822 0.56375265 0.18654354 0.67858637\n",
      " 0.65881409 0.01606243 0.77876512 0.15686986 1.00417377 0.31020238\n",
      " 0.30490643 0.53809306 0.27955219 0.24394203 0.35280317 0.43462197\n",
      " 0.41407783 0.61071738 0.49615756 0.05171499 0.48963473 0.85333146\n",
      " 0.28543073 0.55104153 0.51533333 0.07101351 0.18009192 0.01075838\n",
      " 0.65739501 0.81473406 0.17856095 0.99406622 0.62661798 0.09605029\n",
      " 0.11317728 0.16424002 0.77368985 0.04182595 0.33125535 0.61989606\n",
      " 0.85107144 0.89367918 0.72952453 0.48216614 0.91288381 0.85124631\n",
      " 0.91416678 0.25379503 0.39191414 0.84952834 0.37517079 0.3952442\n",
      " 0.35978925 0.55387142 0.48471695 0.61597373 0.37212153 0.09822301\n",
      " 1.00577896 0.53219904 0.03108096 0.39464607 0.45366089 0.82171096\n",
      " 0.51920409 0.99759375 0.66373787 0.74444978 0.1654027  0.59090807\n",
      " 0.46854348 0.53773878 0.60392096 0.24916462 0.19498935 0.40511054\n",
      " 0.8556156  0.54584183 0.25757891 0.51908318]\n",
      "n_class: 2\n",
      "n_iter: 100\n",
      "actual_value: True \n",
      "\n",
      "\n",
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n",
      "Accuracy: 0.6062992125984252\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.60      0.83      0.70      1051\n",
      "         1.0       0.61      0.33      0.43       854\n",
      "\n",
      "    accuracy                           0.61      1905\n",
      "   macro avg       0.61      0.58      0.56      1905\n",
      "weighted avg       0.61      0.61      0.58      1905\n",
      "\n",
      "\n",
      "Best Parameters:\n",
      " {'learning_rate': 0.1580869299533999, 'n_estimators': 130}\n"
     ]
    }
   ],
   "source": [
    "model_data(df=df1, target='condition1', model = AdaBoostClassifier(), param_dist= param_grid_ab,\n",
    "           n_iter=100, actual_value= True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aebeae14-762d-46ba-9676-b685c1fc36e4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************************************************\n",
      "Running the model task with the following parameters:\n",
      "target: condition1\n",
      "model: SGDClassifier()\n",
      "alpha: [0.0001, 0.001, 0.01, 0.1]\n",
      "max_iter: [6925 3727 5699 3315 5671 8994 3006 8944 7462 5071 7277 6265 7412 7843\n",
      " 7768 7869 4685 9523 2627 5235 5348 2525 7526 8810 7684 9391 8940 5540\n",
      " 4910 2672 6011 7862 1196 5615 9965 8040 2562 4275 2493 5495 7847 9142\n",
      " 1877 5974 6161 7811 8060 8575 8729 4600 2641 6090 4276 4431 1521 7312\n",
      " 8118 8833 5840 2556 1752 9534 1301 9277 1841 5474 6714 6066 6526 5041\n",
      " 3816 5897 6410 4651 4977 5018 3189 3855 4232 2348 9321 2430 5912 4370\n",
      " 7599 8994 7659 3178 5104 4075 6929 8904 9430 1276 9084 6292 7693 3788\n",
      " 8372 4709]\n",
      "tol: [0.001]\n",
      "penalty: ['l2', 'l1', 'elasticnet']\n",
      "n_class: 2\n",
      "n_iter: 100\n",
      "actual_value: True \n",
      "\n",
      "\n",
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n",
      "Accuracy: 0.5921259842519685\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.59      0.89      0.71      1051\n",
      "         1.0       0.62      0.23      0.34       854\n",
      "\n",
      "    accuracy                           0.59      1905\n",
      "   macro avg       0.60      0.56      0.52      1905\n",
      "weighted avg       0.60      0.59      0.54      1905\n",
      "\n",
      "\n",
      "Best Parameters:\n",
      " {'alpha': 0.1, 'max_iter': 3255, 'penalty': 'elasticnet', 'tol': 0.001}\n"
     ]
    }
   ],
   "source": [
    "model_data(df=df1, target='condition1', model = SGDClassifier(), param_dist= param_grid_sgd,\n",
    "           n_iter=100, actual_value= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e85218c-1665-4355-b151-e4f6eb8e996c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_data(df=df1, target='condition1', model = KNeighborsClassifier(), param_dist= param_grid_knn,\n",
    "           n_iter=100, actual_value= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "88ef41f9-cd6e-4e57-98f3-a4d42f1c0090",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************************************************\n",
      "Running the model task with the following parameters:\n",
      "target: condition2\n",
      "model: XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...)\n",
      "max_depth: [6]\n",
      "learning_rate: [0.08812315]\n",
      "n_estimators: [193]\n",
      "subsample: [0.80896294]\n",
      "colsample_bytree: [0.51322753]\n",
      "gamma: [0.01409746]\n",
      "n_class: 2\n",
      "n_iter: 1 \n",
      "\n",
      "\n",
      "Accuracy: 0.5368715083798883\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.58      0.62      0.60       995\n",
      "         1.0       0.48      0.43      0.45       795\n",
      "\n",
      "    accuracy                           0.54      1790\n",
      "   macro avg       0.53      0.53      0.53      1790\n",
      "weighted avg       0.53      0.54      0.53      1790\n",
      "\n",
      "*********************************************************\n",
      "Running the model task with the following parameters:\n",
      "target: condition2\n",
      "model: RandomForestClassifier()\n",
      "n_estimators: [97]\n",
      "max_depth: [7]\n",
      "min_samples_split: [6]\n",
      "min_samples_leaf: [8]\n",
      "n_class: 2\n",
      "n_iter: 1 \n",
      "\n",
      "\n",
      "Accuracy: 0.5659217877094972\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.59      0.74      0.65       995\n",
      "         1.0       0.52      0.35      0.42       795\n",
      "\n",
      "    accuracy                           0.57      1790\n",
      "   macro avg       0.55      0.54      0.54      1790\n",
      "weighted avg       0.56      0.57      0.55      1790\n",
      "\n",
      "*********************************************************\n",
      "Running the model task with the following parameters:\n",
      "target: condition2\n",
      "model: AdaBoostClassifier()\n",
      "n_estimators: [153]\n",
      "learning_rate: [0.90854971]\n",
      "n_class: 2\n",
      "n_iter: 1 \n",
      "\n",
      "\n",
      "Accuracy: 0.5592178770949721\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.59      0.68      0.63       995\n",
      "         1.0       0.50      0.41      0.45       795\n",
      "\n",
      "    accuracy                           0.56      1790\n",
      "   macro avg       0.55      0.54      0.54      1790\n",
      "weighted avg       0.55      0.56      0.55      1790\n",
      "\n",
      "*********************************************************\n",
      "Running the model task with the following parameters:\n",
      "target: condition2\n",
      "model: SGDClassifier()\n",
      "alpha: [0.0001, 0.001, 0.01, 0.1]\n",
      "max_iter: [1867]\n",
      "tol: [0.001]\n",
      "penalty: ['l2', 'l1', 'elasticnet']\n",
      "n_class: 2\n",
      "n_iter: 1 \n",
      "\n",
      "\n",
      "Accuracy: 0.5441340782122905\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.59      0.58      0.59       995\n",
      "         1.0       0.49      0.49      0.49       795\n",
      "\n",
      "    accuracy                           0.54      1790\n",
      "   macro avg       0.54      0.54      0.54      1790\n",
      "weighted avg       0.54      0.54      0.54      1790\n",
      "\n",
      "*********************************************************\n",
      "Running the model task with the following parameters:\n",
      "target: condition2\n",
      "model: KNeighborsClassifier()\n",
      "n_neighbors: [10]\n",
      "weights: ['uniform', 'distance']\n",
      "algorithm: ['ball_tree', 'kd_tree', 'brute']\n",
      "n_class: 2\n",
      "n_iter: 1 \n",
      "\n",
      "\n",
      "Accuracy: 0.5245810055865922\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.57      0.58      0.57       995\n",
      "         1.0       0.46      0.46      0.46       795\n",
      "\n",
      "    accuracy                           0.52      1790\n",
      "   macro avg       0.52      0.52      0.52      1790\n",
      "weighted avg       0.52      0.52      0.52      1790\n",
      "\n",
      "*********************************************************\n",
      "Running the model task with the following parameters:\n",
      "target: condition2\n",
      "model: GaussianNB()\n",
      "n_class: 2\n",
      "n_iter: 1 \n",
      "\n",
      "\n",
      "Accuracy: 0.4480446927374302\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.77      0.01      0.02       995\n",
      "         1.0       0.45      1.00      0.62       795\n",
      "\n",
      "    accuracy                           0.45      1790\n",
      "   macro avg       0.61      0.50      0.32      1790\n",
      "weighted avg       0.63      0.45      0.28      1790\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_data(df=df2, target='condition2', model = xgb.XGBClassifier(), param_dist= param_grid_xgb,\n",
    "           n_iter=1, actual_value= True)\n",
    "model_data(df=df2, target='condition2', model = RandomForestClassifier(), param_dist= param_grid_rf,\n",
    "           n_iter=1, actual_value= True)\n",
    "model_data(df=df2, target='condition2', model = AdaBoostClassifier(), param_dist= param_grid_ab,\n",
    "           n_iter=1, actual_value= True)\n",
    "\n",
    "model_data(df=df2, target='condition2', model = SGDClassifier(), param_dist= param_grid_sgd,\n",
    "           n_iter=1, actual_value= True)\n",
    "\n",
    "model_data(df=df2, target='condition2', model = KNeighborsClassifier(), param_dist= param_grid_knn,\n",
    "           n_iter=1, actual_value= True)\n",
    "\n",
    "model_data(df=df2, target='condition2', model = GaussianNB(), param_dist= param_grid_nb,\n",
    "           n_iter=1, actual_value= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da823e1f-b8a4-4bdf-8a82-cb5e1de7d86a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************************************************\n",
      "Running the model task with the following parameters:\n",
      "target: condition2\n",
      "model: XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...)\n",
      "max_depth: [3 5 9 8 4 6 7 5 3 6]\n",
      "learning_rate: [0.11020404 0.0769275  0.26901342 0.17304578 0.17951997 0.20857812\n",
      " 0.28474779 0.14114351 0.16477706 0.06901436]\n",
      "n_estimators: [142  61 145 142  84 103 156  52 124 178]\n",
      "subsample: [0.7964416  0.87485097 0.80038626 0.65275358 0.98250748 0.76843812\n",
      " 0.84962535 0.61831191 0.98115652 0.73992694]\n",
      "colsample_bytree: [0.58082254 0.57953328 0.68249393 0.69115403 0.72774796 0.88923904\n",
      " 0.56168139 0.85908056 0.99506078 0.9300505 ]\n",
      "gamma: [0.17610745 0.13156633 0.05462394 0.36416096 0.31951791 0.10288923\n",
      " 0.07301267 0.26935542 0.20268392 0.02830929]\n",
      "n_class: 2\n",
      "n_iter: 10\n",
      "actual_value: True \n",
      "\n",
      "\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Accuracy: 0.5795275590551181\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.60      0.82      0.69      1095\n",
      "         1.0       0.51      0.25      0.34       810\n",
      "\n",
      "    accuracy                           0.58      1905\n",
      "   macro avg       0.55      0.54      0.51      1905\n",
      "weighted avg       0.56      0.58      0.54      1905\n",
      "\n",
      "\n",
      "Best Parameters:\n",
      " {'colsample_bytree': 0.5066324805799333, 'gamma': 0.4711008778424264, 'learning_rate': 0.17898646535366178, 'max_depth': 4, 'n_estimators': 58, 'subsample': 0.6063865008880857}\n",
      "*********************************************************\n",
      "Running the model task with the following parameters:\n",
      "target: condition2\n",
      "model: RandomForestClassifier()\n",
      "n_estimators: [189  84 121 117  60 187  87  69  57 120]\n",
      "max_depth: [9 3 5 7 9 4 6 4 9 4]\n",
      "min_samples_split: [3 3 6 2 4 5 9 9 5 4]\n",
      "min_samples_leaf: [8 5 5 6 9 7 5 8 7 7]\n",
      "n_class: 2\n",
      "n_iter: 10\n",
      "actual_value: True \n",
      "\n",
      "\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Accuracy: 0.5748031496062992\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.57      1.00      0.73      1095\n",
      "         1.0       0.00      0.00      0.00       810\n",
      "\n",
      "    accuracy                           0.57      1905\n",
      "   macro avg       0.29      0.50      0.36      1905\n",
      "weighted avg       0.33      0.57      0.42      1905\n",
      "\n",
      "\n",
      "Best Parameters:\n",
      " {'max_depth': 9, 'min_samples_leaf': 4, 'min_samples_split': 6, 'n_estimators': 64}\n",
      "*********************************************************\n",
      "Running the model task with the following parameters:\n",
      "target: condition2\n",
      "model: AdaBoostClassifier()\n",
      "n_estimators: [ 50 192 118  54 103 134  80 192  77  73]\n",
      "learning_rate: [0.58624367 0.42882562 0.50276626 0.6041314  0.88692354 0.09949443\n",
      " 0.50294022 0.50320428 0.07937634 0.72187185]\n",
      "n_class: 2\n",
      "n_iter: 10\n",
      "actual_value: True \n",
      "\n",
      "\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Accuracy: 0.5889763779527559\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.59      0.90      0.72      1095\n",
      "         1.0       0.56      0.16      0.25       810\n",
      "\n",
      "    accuracy                           0.59      1905\n",
      "   macro avg       0.58      0.53      0.48      1905\n",
      "weighted avg       0.58      0.59      0.52      1905\n",
      "\n",
      "\n",
      "Best Parameters:\n",
      " {'learning_rate': 0.1934347898661638, 'n_estimators': 121}\n",
      "*********************************************************\n",
      "Running the model task with the following parameters:\n",
      "target: condition2\n",
      "model: SGDClassifier()\n",
      "alpha: [0.0001, 0.001, 0.01, 0.1]\n",
      "max_iter: [5217 9222 7143 3633 9311 4080 7925 8321 3426 4937]\n",
      "tol: [0.001]\n",
      "penalty: ['l2', 'l1', 'elasticnet']\n",
      "n_class: 2\n",
      "n_iter: 10\n",
      "actual_value: True \n",
      "\n",
      "\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Accuracy: 0.5674540682414698\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.59      0.84      0.69      1095\n",
      "         1.0       0.48      0.20      0.28       810\n",
      "\n",
      "    accuracy                           0.57      1905\n",
      "   macro avg       0.53      0.52      0.48      1905\n",
      "weighted avg       0.54      0.57      0.52      1905\n",
      "\n",
      "\n",
      "Best Parameters:\n",
      " {'alpha': 0.01, 'max_iter': 1860, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "*********************************************************\n",
      "Running the model task with the following parameters:\n",
      "target: condition2\n",
      "model: KNeighborsClassifier()\n",
      "n_neighbors: [ 8  9 27 15 28  5 29  4 13 29]\n",
      "weights: ['uniform', 'distance']\n",
      "algorithm: ['ball_tree', 'kd_tree', 'brute']\n",
      "n_class: 2\n",
      "n_iter: 10\n",
      "actual_value: True \n",
      "\n",
      "\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Accuracy: 0.563254593175853\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.59      0.78      0.67      1095\n",
      "         1.0       0.48      0.27      0.35       810\n",
      "\n",
      "    accuracy                           0.56      1905\n",
      "   macro avg       0.53      0.53      0.51      1905\n",
      "weighted avg       0.54      0.56      0.53      1905\n",
      "\n",
      "\n",
      "Best Parameters:\n",
      " {'algorithm': 'brute', 'n_neighbors': 24, 'weights': 'uniform'}\n",
      "*********************************************************\n",
      "Running the model task with the following parameters:\n",
      "target: condition2\n",
      "model: GaussianNB()\n",
      "n_class: 2\n",
      "n_iter: 10\n",
      "actual_value: True \n",
      "\n",
      "\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Accuracy: 0.42992125984251967\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.01      0.02      1095\n",
      "         1.0       0.43      1.00      0.60       810\n",
      "\n",
      "    accuracy                           0.43      1905\n",
      "   macro avg       0.71      0.50      0.31      1905\n",
      "weighted avg       0.76      0.43      0.26      1905\n",
      "\n",
      "\n",
      "Best Parameters:\n",
      " {}\n"
     ]
    }
   ],
   "source": [
    "model_data(df=df2, target='condition2', model = xgb.XGBClassifier(), param_dist= param_grid_xgb,\n",
    "           n_iter=10, actual_value= True)\n",
    "model_data(df=df2, target='condition2', model = RandomForestClassifier(), param_dist= param_grid_rf,\n",
    "           n_iter=10, actual_value= True)\n",
    "model_data(df=df2, target='condition2', model = AdaBoostClassifier(), param_dist= param_grid_ab,\n",
    "           n_iter=10, actual_value= True)\n",
    "\n",
    "model_data(df=df2, target='condition2', model = SGDClassifier(), param_dist= param_grid_sgd,\n",
    "           n_iter=10, actual_value= True)\n",
    "\n",
    "model_data(df=df2, target='condition2', model = KNeighborsClassifier(), param_dist= param_grid_knn,\n",
    "           n_iter=10, actual_value= True)\n",
    "\n",
    "model_data(df=df2, target='condition2', model = GaussianNB(), param_dist= param_grid_nb,\n",
    "           n_iter=10, actual_value= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "70456912-34d3-4528-a7f0-f3230e3ee992",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.,  1.,  0.])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['condition1'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b0b1c9-f674-4167-b583-e60b63b9a31e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 3 class model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2bc2768f-1180-4711-b91d-2409391cabb6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************************************************\n",
      "Running the model task with the following parameters:\n",
      "target: condition1\n",
      "model: XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...)\n",
      "max_depth: [3, 4, 5]\n",
      "learning_rate: [0.01, 0.05, 0.1]\n",
      "n_class: 3\n",
      "n_iter: 1\n",
      "actual_value: True \n",
      "\n",
      "\n",
      "Accuracy: 0.5475065616797901\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.60      0.06      0.11        95\n",
      "         1.0       0.54      0.46      0.50       854\n",
      "         2.0       0.55      0.67      0.60       956\n",
      "\n",
      "    accuracy                           0.55      1905\n",
      "   macro avg       0.56      0.40      0.41      1905\n",
      "weighted avg       0.55      0.55      0.53      1905\n",
      "\n",
      "*********************************************************\n",
      "Running the model task with the following parameters:\n",
      "target: condition1\n",
      "model: RandomForestClassifier()\n",
      "n_estimators: [71]\n",
      "max_depth: [7]\n",
      "min_samples_split: [7]\n",
      "min_samples_leaf: [6]\n",
      "n_class: 3\n",
      "n_iter: 1\n",
      "actual_value: True \n",
      "\n",
      "\n",
      "Accuracy: 0.558005249343832\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.08      0.15        95\n",
      "         1.0       0.56      0.48      0.52       854\n",
      "         2.0       0.56      0.67      0.61       956\n",
      "\n",
      "    accuracy                           0.56      1905\n",
      "   macro avg       0.67      0.41      0.43      1905\n",
      "weighted avg       0.57      0.56      0.54      1905\n",
      "\n",
      "*********************************************************\n",
      "Running the model task with the following parameters:\n",
      "target: condition1\n",
      "model: AdaBoostClassifier()\n",
      "n_estimators: [110]\n",
      "learning_rate: [0.33607308]\n",
      "n_class: 3\n",
      "n_iter: 1\n",
      "actual_value: True \n",
      "\n",
      "\n",
      "Accuracy: 0.552755905511811\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.20      0.01      0.02        95\n",
      "         1.0       0.57      0.42      0.48       854\n",
      "         2.0       0.55      0.72      0.62       956\n",
      "\n",
      "    accuracy                           0.55      1905\n",
      "   macro avg       0.44      0.39      0.38      1905\n",
      "weighted avg       0.54      0.55      0.53      1905\n",
      "\n",
      "*********************************************************\n",
      "Running the model task with the following parameters:\n",
      "target: condition1\n",
      "model: SGDClassifier()\n",
      "alpha: [0.0001, 0.001, 0.01, 0.1]\n",
      "max_iter: [5796]\n",
      "tol: [0.001]\n",
      "penalty: ['l2', 'l1', 'elasticnet']\n",
      "n_class: 3\n",
      "n_iter: 1\n",
      "actual_value: True \n",
      "\n",
      "\n",
      "Accuracy: 0.521259842519685\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.22      0.11      0.14        95\n",
      "         1.0       0.52      0.30      0.38       854\n",
      "         2.0       0.53      0.76      0.62       956\n",
      "\n",
      "    accuracy                           0.52      1905\n",
      "   macro avg       0.42      0.39      0.38      1905\n",
      "weighted avg       0.51      0.52      0.49      1905\n",
      "\n",
      "*********************************************************\n",
      "Running the model task with the following parameters:\n",
      "target: condition1\n",
      "model: KNeighborsClassifier()\n",
      "n_neighbors: [20]\n",
      "weights: ['uniform', 'distance']\n",
      "algorithm: ['ball_tree', 'kd_tree', 'brute']\n",
      "n_class: 3\n",
      "n_iter: 1\n",
      "actual_value: True \n",
      "\n",
      "\n",
      "Accuracy: 0.5086614173228347\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.22      0.14      0.17        95\n",
      "         1.0       0.50      0.48      0.49       854\n",
      "         2.0       0.54      0.57      0.55       956\n",
      "\n",
      "    accuracy                           0.51      1905\n",
      "   macro avg       0.42      0.40      0.40      1905\n",
      "weighted avg       0.50      0.51      0.50      1905\n",
      "\n",
      "*********************************************************\n",
      "Running the model task with the following parameters:\n",
      "target: condition1\n",
      "model: GaussianNB()\n",
      "n_class: 3\n",
      "n_iter: 1\n",
      "actual_value: True \n",
      "\n",
      "\n",
      "Accuracy: 0.08766404199475065\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.05      0.99      0.10        95\n",
      "         1.0       0.54      0.09      0.15       854\n",
      "         2.0       0.00      0.00      0.00       956\n",
      "\n",
      "    accuracy                           0.09      1905\n",
      "   macro avg       0.20      0.36      0.08      1905\n",
      "weighted avg       0.25      0.09      0.07      1905\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_data(df=df1, target='condition1', model = xgb.XGBClassifier(), param_dist= param_grid_xgb,\n",
    "           n_iter=1, actual_value= True, n_class=3)\n",
    "model_data(df=df1, target='condition1', model = RandomForestClassifier(), param_dist= param_grid_rf,\n",
    "           n_iter=1, actual_value= True, n_class=3)\n",
    "model_data(df=df1, target='condition1', model = AdaBoostClassifier(), param_dist= param_grid_ab,\n",
    "           n_iter=1, actual_value= True, n_class=3)\n",
    "\n",
    "model_data(df=df1, target='condition1', model = SGDClassifier(), param_dist= param_grid_sgd,\n",
    "           n_iter=1, actual_value= True, n_class=3)\n",
    "\n",
    "model_data(df=df1, target='condition1', model = KNeighborsClassifier(), param_dist= param_grid_knn,\n",
    "           n_iter=1, actual_value= True, n_class=3)\n",
    "\n",
    "model_data(df=df1, target='condition1', model = GaussianNB(), param_dist= param_grid_nb,\n",
    "           n_iter=1, actual_value= True, n_class=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f4de3807-5388-4c0e-b9d3-d1effcce4d72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************************************************\n",
      "Running the model task with the following parameters:\n",
      "target: condition1\n",
      "model: XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...)\n",
      "max_depth: [3, 4, 5]\n",
      "learning_rate: [0.01, 0.05, 0.1]\n",
      "n_class: 3\n",
      "n_iter: 1\n",
      "actual_value: False \n",
      "\n",
      "\n",
      "Accuracy: 0.5480314960629922\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.70      0.07      0.13        95\n",
      "         1.0       0.54      0.45      0.49       854\n",
      "         2.0       0.55      0.68      0.61       956\n",
      "\n",
      "    accuracy                           0.55      1905\n",
      "   macro avg       0.60      0.40      0.41      1905\n",
      "weighted avg       0.55      0.55      0.53      1905\n",
      "\n",
      "*********************************************************\n",
      "Running the model task with the following parameters:\n",
      "target: condition1\n",
      "model: RandomForestClassifier()\n",
      "n_estimators: [51]\n",
      "max_depth: [6]\n",
      "min_samples_split: [2]\n",
      "min_samples_leaf: [5]\n",
      "n_class: 3\n",
      "n_iter: 1\n",
      "actual_value: False \n",
      "\n",
      "\n",
      "Accuracy: 0.5548556430446194\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.83      0.05      0.10        95\n",
      "         1.0       0.55      0.49      0.52       854\n",
      "         2.0       0.56      0.66      0.60       956\n",
      "\n",
      "    accuracy                           0.55      1905\n",
      "   macro avg       0.65      0.40      0.41      1905\n",
      "weighted avg       0.57      0.55      0.54      1905\n",
      "\n",
      "*********************************************************\n",
      "Running the model task with the following parameters:\n",
      "target: condition1\n",
      "model: AdaBoostClassifier()\n",
      "n_estimators: [70]\n",
      "learning_rate: [0.14393958]\n",
      "n_class: 3\n",
      "n_iter: 1\n",
      "actual_value: False \n",
      "\n",
      "\n",
      "Accuracy: 0.5532808398950131\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.17      0.01      0.02        95\n",
      "         1.0       0.57      0.43      0.49       854\n",
      "         2.0       0.55      0.72      0.62       956\n",
      "\n",
      "    accuracy                           0.55      1905\n",
      "   macro avg       0.43      0.39      0.38      1905\n",
      "weighted avg       0.54      0.55      0.53      1905\n",
      "\n",
      "*********************************************************\n",
      "Running the model task with the following parameters:\n",
      "target: condition1\n",
      "model: SGDClassifier()\n",
      "alpha: [0.0001, 0.001, 0.01, 0.1]\n",
      "max_iter: [3489]\n",
      "tol: [0.001]\n",
      "penalty: ['l2', 'l1', 'elasticnet']\n",
      "n_class: 3\n",
      "n_iter: 1\n",
      "actual_value: False \n",
      "\n",
      "\n",
      "Accuracy: 0.5154855643044619\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.13      0.13      0.13        95\n",
      "         1.0       0.52      0.55      0.53       854\n",
      "         2.0       0.55      0.52      0.54       956\n",
      "\n",
      "    accuracy                           0.52      1905\n",
      "   macro avg       0.40      0.40      0.40      1905\n",
      "weighted avg       0.52      0.52      0.52      1905\n",
      "\n",
      "*********************************************************\n",
      "Running the model task with the following parameters:\n",
      "target: condition1\n",
      "model: KNeighborsClassifier()\n",
      "n_neighbors: [23]\n",
      "weights: ['uniform', 'distance']\n",
      "algorithm: ['ball_tree', 'kd_tree', 'brute']\n",
      "n_class: 3\n",
      "n_iter: 1\n",
      "actual_value: False \n",
      "\n",
      "\n",
      "Accuracy: 0.5086614173228347\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.23      0.15      0.18        95\n",
      "         1.0       0.49      0.48      0.48       854\n",
      "         2.0       0.54      0.57      0.55       956\n",
      "\n",
      "    accuracy                           0.51      1905\n",
      "   macro avg       0.42      0.40      0.41      1905\n",
      "weighted avg       0.50      0.51      0.50      1905\n",
      "\n",
      "*********************************************************\n",
      "Running the model task with the following parameters:\n",
      "target: condition1\n",
      "model: GaussianNB()\n",
      "n_class: 3\n",
      "n_iter: 1\n",
      "actual_value: False \n",
      "\n",
      "\n",
      "Accuracy: 0.08766404199475065\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.05      0.99      0.10        95\n",
      "         1.0       0.54      0.09      0.15       854\n",
      "         2.0       0.00      0.00      0.00       956\n",
      "\n",
      "    accuracy                           0.09      1905\n",
      "   macro avg       0.20      0.36      0.08      1905\n",
      "weighted avg       0.25      0.09      0.07      1905\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_data(df=df1, target='condition1', model = xgb.XGBClassifier(), param_dist= param_grid_xgb,\n",
    "           n_iter=1, actual_value= False, n_class=3)\n",
    "model_data(df=df1, target='condition1', model = RandomForestClassifier(), param_dist= param_grid_rf,\n",
    "           n_iter=1, actual_value= False, n_class=3)\n",
    "model_data(df=df1, target='condition1', model = AdaBoostClassifier(), param_dist= param_grid_ab,\n",
    "           n_iter=1, actual_value= False, n_class=3)\n",
    "\n",
    "model_data(df=df1, target='condition1', model = SGDClassifier(), param_dist= param_grid_sgd,\n",
    "           n_iter=1, actual_value= False, n_class=3)\n",
    "\n",
    "model_data(df=df1, target='condition1', model = KNeighborsClassifier(), param_dist= param_grid_knn,\n",
    "           n_iter=1, actual_value= False, n_class=3)\n",
    "\n",
    "model_data(df=df1, target='condition1', model = GaussianNB(), param_dist= param_grid_nb,\n",
    "           n_iter=1, actual_value= False, n_class=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81c4b1f6-973c-4cf2-86a8-cc26105b8ca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************************************************\n",
      "Running the model task with the following parameters:\n",
      "target: condition2\n",
      "model: XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...)\n",
      "max_depth: [8]\n",
      "learning_rate: [0.07170901]\n",
      "n_estimators: [135]\n",
      "subsample: [0.71166701]\n",
      "colsample_bytree: [0.83643662]\n",
      "gamma: [0.23825345]\n",
      "n_class: 3\n",
      "n_iter: 1\n",
      "actual_value: True \n",
      "\n",
      "\n",
      "Accuracy: 0.5196850393700787\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.55      0.10      0.17       122\n",
      "         1.0       0.49      0.44      0.46       810\n",
      "         2.0       0.54      0.64      0.59       973\n",
      "\n",
      "    accuracy                           0.52      1905\n",
      "   macro avg       0.52      0.39      0.40      1905\n",
      "weighted avg       0.52      0.52      0.51      1905\n",
      "\n",
      "*********************************************************\n",
      "Running the model task with the following parameters:\n",
      "target: condition2\n",
      "model: RandomForestClassifier()\n",
      "n_estimators: [155]\n",
      "max_depth: [6]\n",
      "min_samples_split: [2]\n",
      "min_samples_leaf: [9]\n",
      "n_class: 3\n",
      "n_iter: 1\n",
      "actual_value: True \n",
      "\n",
      "\n",
      "Accuracy: 0.5091863517060368\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.71      0.08      0.15       122\n",
      "         1.0       0.46      0.36      0.41       810\n",
      "         2.0       0.53      0.69      0.60       973\n",
      "\n",
      "    accuracy                           0.51      1905\n",
      "   macro avg       0.57      0.38      0.38      1905\n",
      "weighted avg       0.51      0.51      0.49      1905\n",
      "\n",
      "*********************************************************\n",
      "Running the model task with the following parameters:\n",
      "target: condition2\n",
      "model: AdaBoostClassifier()\n",
      "n_estimators: [174]\n",
      "learning_rate: [0.49555834]\n",
      "n_class: 3\n",
      "n_iter: 1\n",
      "actual_value: True \n",
      "\n",
      "\n",
      "Accuracy: 0.5123359580052493\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.33      0.02      0.05       122\n",
      "         1.0       0.48      0.29      0.36       810\n",
      "         2.0       0.52      0.76      0.62       973\n",
      "\n",
      "    accuracy                           0.51      1905\n",
      "   macro avg       0.45      0.36      0.34      1905\n",
      "weighted avg       0.49      0.51      0.47      1905\n",
      "\n",
      "*********************************************************\n",
      "Running the model task with the following parameters:\n",
      "target: condition2\n",
      "model: SGDClassifier()\n",
      "alpha: [0.0001, 0.001, 0.01, 0.1]\n",
      "max_iter: [9287]\n",
      "tol: [0.001]\n",
      "penalty: ['l2', 'l1', 'elasticnet']\n",
      "n_class: 3\n",
      "n_iter: 1\n",
      "actual_value: True \n",
      "\n",
      "\n",
      "Accuracy: 0.4005249343832021\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.09      0.30      0.14       122\n",
      "         1.0       0.45      0.43      0.44       810\n",
      "         2.0       0.51      0.39      0.44       973\n",
      "\n",
      "    accuracy                           0.40      1905\n",
      "   macro avg       0.35      0.37      0.34      1905\n",
      "weighted avg       0.46      0.40      0.42      1905\n",
      "\n",
      "*********************************************************\n",
      "Running the model task with the following parameters:\n",
      "target: condition2\n",
      "model: KNeighborsClassifier()\n",
      "n_neighbors: [24]\n",
      "weights: ['uniform', 'distance']\n",
      "algorithm: ['ball_tree', 'kd_tree', 'brute']\n",
      "n_class: 3\n",
      "n_iter: 1\n",
      "actual_value: True \n",
      "\n",
      "\n",
      "Accuracy: 0.47874015748031495\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.22      0.16      0.19       122\n",
      "         1.0       0.45      0.51      0.48       810\n",
      "         2.0       0.53      0.49      0.51       973\n",
      "\n",
      "    accuracy                           0.48      1905\n",
      "   macro avg       0.40      0.39      0.39      1905\n",
      "weighted avg       0.48      0.48      0.48      1905\n",
      "\n",
      "*********************************************************\n",
      "Running the model task with the following parameters:\n",
      "target: condition2\n",
      "model: GaussianNB()\n",
      "n_class: 3\n",
      "n_iter: 1\n",
      "actual_value: True \n",
      "\n",
      "\n",
      "Accuracy: 0.08503937007874016\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.07      0.99      0.12       122\n",
      "         1.0       0.45      0.04      0.08       810\n",
      "         2.0       0.86      0.01      0.01       973\n",
      "\n",
      "    accuracy                           0.09      1905\n",
      "   macro avg       0.46      0.35      0.07      1905\n",
      "weighted avg       0.64      0.09      0.05      1905\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_data(df=df2, target='condition2', model = xgb.XGBClassifier(), param_dist= param_grid_xgb,\n",
    "           n_iter=1, actual_value= True, n_class=3)\n",
    "model_data(df=df2, target='condition2', model = RandomForestClassifier(), param_dist= param_grid_rf,\n",
    "           n_iter=1, actual_value= True, n_class=3)\n",
    "model_data(df=df2, target='condition2', model = AdaBoostClassifier(), param_dist= param_grid_ab,\n",
    "           n_iter=1, actual_value= True, n_class=3)\n",
    "\n",
    "model_data(df=df2, target='condition2', model = SGDClassifier(), param_dist= param_grid_sgd,\n",
    "           n_iter=1, actual_value= True, n_class=3)\n",
    "\n",
    "model_data(df=df2, target='condition2', model = KNeighborsClassifier(), param_dist= param_grid_knn,\n",
    "           n_iter=1, actual_value= True, n_class=3)\n",
    "\n",
    "model_data(df=df2, target='condition2', model = GaussianNB(), param_dist= param_grid_nb,\n",
    "           n_iter=1, actual_value= True ,n_class=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6e7ff829-be93-4e36-bb10-10bb49165419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************************************************\n",
      "Running the model task with the following parameters:\n",
      "target: condition2\n",
      "model: XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...)\n",
      "max_depth: [3, 4, 5]\n",
      "learning_rate: [0.01, 0.05, 0.1]\n",
      "n_class: 2\n",
      "n_iter: 1\n",
      "actual_value: False \n",
      "\n",
      "\n",
      "Accuracy: 0.5658792650918635\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.60      0.74      0.66      1095\n",
      "         1.0       0.48      0.33      0.39       810\n",
      "\n",
      "    accuracy                           0.57      1905\n",
      "   macro avg       0.54      0.54      0.53      1905\n",
      "weighted avg       0.55      0.57      0.55      1905\n",
      "\n",
      "*********************************************************\n",
      "Running the model task with the following parameters:\n",
      "target: condition2\n",
      "model: RandomForestClassifier()\n",
      "n_estimators: [115]\n",
      "max_depth: [6]\n",
      "min_samples_split: [8]\n",
      "min_samples_leaf: [2]\n",
      "n_class: 2\n",
      "n_iter: 1\n",
      "actual_value: False \n",
      "\n",
      "\n",
      "Accuracy: 0.5758530183727034\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.59      0.83      0.69      1095\n",
      "         1.0       0.50      0.23      0.32       810\n",
      "\n",
      "    accuracy                           0.58      1905\n",
      "   macro avg       0.55      0.53      0.51      1905\n",
      "weighted avg       0.56      0.58      0.53      1905\n",
      "\n",
      "*********************************************************\n",
      "Running the model task with the following parameters:\n",
      "target: condition2\n",
      "model: AdaBoostClassifier()\n",
      "n_estimators: [129]\n",
      "learning_rate: [0.93052777]\n",
      "n_class: 2\n",
      "n_iter: 1\n",
      "actual_value: False \n",
      "\n",
      "\n",
      "Accuracy: 0.5889763779527559\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.60      0.83      0.70      1095\n",
      "         1.0       0.53      0.26      0.35       810\n",
      "\n",
      "    accuracy                           0.59      1905\n",
      "   macro avg       0.57      0.55      0.53      1905\n",
      "weighted avg       0.57      0.59      0.55      1905\n",
      "\n",
      "*********************************************************\n",
      "Running the model task with the following parameters:\n",
      "target: condition2\n",
      "model: SGDClassifier()\n",
      "alpha: [0.0001, 0.001, 0.01, 0.1]\n",
      "max_iter: [1974]\n",
      "tol: [0.001]\n",
      "penalty: ['l2', 'l1', 'elasticnet']\n",
      "n_class: 2\n",
      "n_iter: 1\n",
      "actual_value: False \n",
      "\n",
      "\n",
      "Accuracy: 0.5401574803149606\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.57      0.78      0.66      1095\n",
      "         1.0       0.42      0.21      0.28       810\n",
      "\n",
      "    accuracy                           0.54      1905\n",
      "   macro avg       0.50      0.50      0.47      1905\n",
      "weighted avg       0.51      0.54      0.50      1905\n",
      "\n",
      "*********************************************************\n",
      "Running the model task with the following parameters:\n",
      "target: condition2\n",
      "model: KNeighborsClassifier()\n",
      "n_neighbors: [14]\n",
      "weights: ['uniform', 'distance']\n",
      "algorithm: ['ball_tree', 'kd_tree', 'brute']\n",
      "n_class: 2\n",
      "n_iter: 1\n",
      "actual_value: False \n",
      "\n",
      "\n",
      "Accuracy: 0.5343832020997376\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.59      0.62      0.60      1095\n",
      "         1.0       0.45      0.42      0.44       810\n",
      "\n",
      "    accuracy                           0.53      1905\n",
      "   macro avg       0.52      0.52      0.52      1905\n",
      "weighted avg       0.53      0.53      0.53      1905\n",
      "\n",
      "*********************************************************\n",
      "Running the model task with the following parameters:\n",
      "target: condition2\n",
      "model: GaussianNB()\n",
      "n_class: 2\n",
      "n_iter: 1\n",
      "actual_value: False \n",
      "\n",
      "\n",
      "Accuracy: 0.42992125984251967\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.01      0.02      1095\n",
      "         1.0       0.43      1.00      0.60       810\n",
      "\n",
      "    accuracy                           0.43      1905\n",
      "   macro avg       0.71      0.50      0.31      1905\n",
      "weighted avg       0.76      0.43      0.26      1905\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_data(df=df2, target='condition2', model = xgb.XGBClassifier(), param_dist= param_grid_xgb,\n",
    "           n_iter=1, actual_value= False)\n",
    "model_data(df=df2, target='condition2', model = RandomForestClassifier(), param_dist= param_grid_rf,\n",
    "           n_iter=1, actual_value= False)\n",
    "model_data(df=df2, target='condition2', model = AdaBoostClassifier(), param_dist= param_grid_ab,\n",
    "           n_iter=1, actual_value= False)\n",
    "\n",
    "model_data(df=df2, target='condition2', model = SGDClassifier(), param_dist= param_grid_sgd,\n",
    "           n_iter=1, actual_value= False)\n",
    "\n",
    "model_data(df=df2, target='condition2', model = KNeighborsClassifier(), param_dist= param_grid_knn,\n",
    "           n_iter=1, actual_value= False)\n",
    "\n",
    "model_data(df=df2, target='condition2', model = GaussianNB(), param_dist= param_grid_nb,\n",
    "           n_iter=1, actual_value= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5369ce5d-78a9-4293-9625-919868380899",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aaa3c81-51b7-4502-b2f8-75c0be16b34d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4bc934d2-c261-4625-8083-06fc868637e4",
   "metadata": {},
   "source": [
    "# Base and optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d43483f2-fd5c-4aa3-ac3d-be28af2a4935",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************************************************\n",
      "Running the model task with the following parameters:\n",
      "target: condition1\n",
      "model: XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...)\n",
      "max_depth: [9]\n",
      "learning_rate: [0.09129576]\n",
      "n_estimators: [100]\n",
      "subsample: [0.88929258]\n",
      "colsample_bytree: [0.66862218]\n",
      "gamma: [0.2662527]\n",
      "n_class: 2\n",
      "n_iter: 1 \n",
      "\n",
      "\n",
      "Accuracy: 0.5896589658965896\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.61      0.69      0.64       981\n",
      "         1.0       0.57      0.47      0.51       837\n",
      "\n",
      "    accuracy                           0.59      1818\n",
      "   macro avg       0.59      0.58      0.58      1818\n",
      "weighted avg       0.59      0.59      0.58      1818\n",
      "\n",
      "*********************************************************\n",
      "Running the model task with the following parameters:\n",
      "target: condition1\n",
      "model: XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...)\n",
      "max_depth: [8 4 3 8 5 4 6 7 5 7]\n",
      "learning_rate: [0.01370867 0.0657928  0.17138778 0.15621286 0.08851799 0.24390788\n",
      " 0.13266502 0.16139297 0.29719943 0.25425823]\n",
      "n_estimators: [139  66 116  88 129 171 118  98 193 189]\n",
      "subsample: [0.66677367 0.81269347 0.97473741 0.91301974 0.96668348 0.89843076\n",
      " 0.92772355 0.89788411 0.94760671 0.70586592]\n",
      "colsample_bytree: [0.92046186 0.85944618 0.61455807 0.53861265 0.66309651 0.94198024\n",
      " 0.93287743 0.95025679 0.67534858 0.8671262 ]\n",
      "gamma: [0.30716266 0.10679665 0.07684792 0.46175633 0.28428616 0.38273098\n",
      " 0.01367414 0.15085163 0.48795179 0.33936452]\n",
      "n_class: 2\n",
      "n_iter: 10 \n",
      "\n",
      "\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Accuracy: 0.5869086908690869\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.60      0.70      0.65       981\n",
      "         1.0       0.56      0.45      0.50       837\n",
      "\n",
      "    accuracy                           0.59      1818\n",
      "   macro avg       0.58      0.58      0.57      1818\n",
      "weighted avg       0.58      0.59      0.58      1818\n",
      "\n",
      "\n",
      "Best Parameters:\n",
      " {'colsample_bytree': 0.8059264473611898, 'gamma': 0.06974693032602092, 'learning_rate': 0.09764339456056544, 'max_depth': 9, 'n_estimators': 100, 'subsample': 0.7529847965068651}\n"
     ]
    }
   ],
   "source": [
    "model_data(df=df1, target='condition1', model = xgb.XGBClassifier(), param_dist= param_grid_xgb,n_iter=1)\n",
    "model_data(df=df1, target='condition1', model = xgb.XGBClassifier(), param_dist= param_grid_xgb,n_iter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cf524907-eb72-4c30-a739-fbf9d9b018e1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************************************************\n",
      "Running the model task with the following parameters:\n",
      "target: condition1\n",
      "model: RandomForestClassifier()\n",
      "n_estimators: [108]\n",
      "max_depth: [6]\n",
      "min_samples_split: [7]\n",
      "min_samples_leaf: [7]\n",
      "n_class: 2\n",
      "n_iter: 1 \n",
      "\n",
      "\n",
      "Accuracy: 0.588008800880088\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.60      0.71      0.65       981\n",
      "         1.0       0.57      0.44      0.50       837\n",
      "\n",
      "    accuracy                           0.59      1818\n",
      "   macro avg       0.58      0.58      0.57      1818\n",
      "weighted avg       0.58      0.59      0.58      1818\n",
      "\n",
      "*********************************************************\n",
      "Running the model task with the following parameters:\n",
      "target: condition1\n",
      "model: RandomForestClassifier()\n",
      "n_estimators: [ 66 109  73  84 108 165 197 189  93  97]\n",
      "max_depth: [7 5 9 8 7 8 7 7 8 6]\n",
      "min_samples_split: [8 9 4 6 2 9 7 8 8 6]\n",
      "min_samples_leaf: [1 5 2 2 7 9 7 9 7 5]\n",
      "n_class: 2\n",
      "n_iter: 10 \n",
      "\n",
      "\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Accuracy: 0.555005500550055\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.55      0.96      0.70       981\n",
      "         1.0       0.62      0.08      0.15       837\n",
      "\n",
      "    accuracy                           0.56      1818\n",
      "   macro avg       0.59      0.52      0.42      1818\n",
      "weighted avg       0.58      0.56      0.45      1818\n",
      "\n",
      "\n",
      "Best Parameters:\n",
      " {'max_depth': 5, 'min_samples_leaf': 8, 'min_samples_split': 6, 'n_estimators': 149}\n"
     ]
    }
   ],
   "source": [
    "model_data(df=df1, target='condition1', model = RandomForestClassifier(), param_dist= param_grid_rf,n_iter=1)\n",
    "model_data(df=df1, target='condition1', model = RandomForestClassifier(), param_dist= param_grid_rf,n_iter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a09fc465-7358-4498-9a39-05cc2498109a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************************************************\n",
      "Running the model task with the following parameters:\n",
      "target: condition1\n",
      "model: AdaBoostClassifier()\n",
      "n_estimators: [199]\n",
      "learning_rate: [0.32051402]\n",
      "n_class: 2\n",
      "n_iter: 1 \n",
      "\n",
      "\n",
      "Accuracy: 0.6056105610561056\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.61      0.75      0.67       981\n",
      "         1.0       0.60      0.43      0.50       837\n",
      "\n",
      "    accuracy                           0.61      1818\n",
      "   macro avg       0.60      0.59      0.59      1818\n",
      "weighted avg       0.60      0.61      0.59      1818\n",
      "\n",
      "*********************************************************\n",
      "Running the model task with the following parameters:\n",
      "target: condition1\n",
      "model: AdaBoostClassifier()\n",
      "n_estimators: [178  71  66 176  75  95 100 152 141  76]\n",
      "learning_rate: [0.22497884 0.37645835 0.75698977 0.76657604 0.79601236 0.54218522\n",
      " 0.11612226 0.42038203 0.32578356 0.28051177]\n",
      "n_class: 2\n",
      "n_iter: 10 \n",
      "\n",
      "\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Accuracy: 0.5885588558855885\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.59      0.77      0.67       981\n",
      "         1.0       0.58      0.38      0.46       837\n",
      "\n",
      "    accuracy                           0.59      1818\n",
      "   macro avg       0.59      0.57      0.56      1818\n",
      "weighted avg       0.59      0.59      0.57      1818\n",
      "\n",
      "\n",
      "Best Parameters:\n",
      " {'learning_rate': 0.1934347898661638, 'n_estimators': 121}\n"
     ]
    }
   ],
   "source": [
    "model_data(df=df1, target='condition1', model = AdaBoostClassifier(), param_dist= param_grid_ab,n_iter=1)\n",
    "model_data(df=df1, target='condition1', model = AdaBoostClassifier(), param_dist= param_grid_ab,n_iter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3ab6c0e2-ff81-4222-8a76-023ab3d5d1ae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************************************************\n",
      "Running the model task with the following parameters:\n",
      "target: condition1\n",
      "model: SGDClassifier()\n",
      "alpha: [0.0001, 0.001, 0.01, 0.1]\n",
      "max_iter: [2035]\n",
      "tol: [0.001]\n",
      "penalty: ['l2', 'l1', 'elasticnet']\n",
      "n_class: 2\n",
      "n_iter: 1 \n",
      "\n",
      "\n",
      "Accuracy: 0.5473047304730473\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.56      0.81      0.66       981\n",
      "         1.0       0.52      0.24      0.33       837\n",
      "\n",
      "    accuracy                           0.55      1818\n",
      "   macro avg       0.54      0.52      0.49      1818\n",
      "weighted avg       0.54      0.55      0.51      1818\n",
      "\n",
      "*********************************************************\n",
      "Running the model task with the following parameters:\n",
      "target: condition1\n",
      "model: SGDClassifier()\n",
      "alpha: [0.0001, 0.001, 0.01, 0.1]\n",
      "max_iter: [2766 6024 7429 7402 5445 2064 8843 6929 1210 9808]\n",
      "tol: [0.001]\n",
      "penalty: ['l2', 'l1', 'elasticnet']\n",
      "n_class: 2\n",
      "n_iter: 10 \n",
      "\n",
      "\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Accuracy: 0.5687568756875687\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.57      0.82      0.67       981\n",
      "         1.0       0.56      0.28      0.37       837\n",
      "\n",
      "    accuracy                           0.57      1818\n",
      "   macro avg       0.57      0.55      0.52      1818\n",
      "weighted avg       0.57      0.57      0.53      1818\n",
      "\n",
      "\n",
      "Best Parameters:\n",
      " {'alpha': 0.0001, 'max_iter': 6734, 'penalty': 'l1', 'tol': 0.001}\n"
     ]
    }
   ],
   "source": [
    "model_data(df=df1, target='condition1', model = SGDClassifier(), param_dist= param_grid_sgd,n_iter=1)\n",
    "model_data(df=df1, target='condition1', model = SGDClassifier(), param_dist= param_grid_sgd,n_iter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "005d91b3-c523-410f-beb0-964259ac0c48",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************************************************\n",
      "Running the model task with the following parameters:\n",
      "target: condition1\n",
      "model: KNeighborsClassifier()\n",
      "n_neighbors: [17]\n",
      "weights: ['uniform', 'distance']\n",
      "algorithm: ['ball_tree', 'kd_tree', 'brute']\n",
      "n_class: 2\n",
      "n_iter: 1 \n",
      "\n",
      "\n",
      "Accuracy: 0.5484048404840484\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.58      0.62      0.60       981\n",
      "         1.0       0.51      0.46      0.49       837\n",
      "\n",
      "    accuracy                           0.55      1818\n",
      "   macro avg       0.54      0.54      0.54      1818\n",
      "weighted avg       0.55      0.55      0.55      1818\n",
      "\n",
      "*********************************************************\n",
      "Running the model task with the following parameters:\n",
      "target: condition1\n",
      "model: KNeighborsClassifier()\n",
      "n_neighbors: [25 14 12  7 18  8  5 15  6  7]\n",
      "weights: ['uniform', 'distance']\n",
      "algorithm: ['ball_tree', 'kd_tree', 'brute']\n",
      "n_class: 2\n",
      "n_iter: 10 \n",
      "\n",
      "\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Accuracy: 0.5715071507150715\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.58      0.75      0.65       981\n",
      "         1.0       0.55      0.37      0.44       837\n",
      "\n",
      "    accuracy                           0.57      1818\n",
      "   macro avg       0.57      0.56      0.55      1818\n",
      "weighted avg       0.57      0.57      0.56      1818\n",
      "\n",
      "\n",
      "Best Parameters:\n",
      " {'algorithm': 'brute', 'n_neighbors': 24, 'weights': 'uniform'}\n"
     ]
    }
   ],
   "source": [
    "model_data(df=df1, target='condition1', model = KNeighborsClassifier(), param_dist= param_grid_knn,n_iter=1)\n",
    "model_data(df=df1, target='condition1', model = KNeighborsClassifier(), param_dist= param_grid_knn,n_iter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6e326179-53c4-46b7-ade0-1306153a9648",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************************************************\n",
      "Running the model task with the following parameters:\n",
      "target: condition1\n",
      "model: GaussianNB()\n",
      "n_class: 2\n",
      "n_iter: 1 \n",
      "\n",
      "\n",
      "Accuracy: 0.45764576457645767\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       981\n",
      "         1.0       0.46      0.99      0.63       837\n",
      "\n",
      "    accuracy                           0.46      1818\n",
      "   macro avg       0.23      0.50      0.31      1818\n",
      "weighted avg       0.21      0.46      0.29      1818\n",
      "\n",
      "*********************************************************\n",
      "Running the model task with the following parameters:\n",
      "target: condition1\n",
      "model: GaussianNB()\n",
      "n_class: 2\n",
      "n_iter: 10 \n",
      "\n",
      "\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Accuracy: 0.45764576457645767\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       981\n",
      "         1.0       0.46      0.99      0.63       837\n",
      "\n",
      "    accuracy                           0.46      1818\n",
      "   macro avg       0.23      0.50      0.31      1818\n",
      "weighted avg       0.21      0.46      0.29      1818\n",
      "\n",
      "\n",
      "Best Parameters:\n",
      " {}\n"
     ]
    }
   ],
   "source": [
    "model_data(df=df1, target='condition1', model = GaussianNB(), param_dist= param_grid_nb,n_iter=1)\n",
    "model_data(df=df1, target='condition1', model = GaussianNB(), param_dist= param_grid_nb,n_iter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3741d5f3-e4ab-4feb-8a6f-b8ea58ce20c1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************************************************\n",
      "Running the model task with the following parameters:\n",
      "target: condition2\n",
      "model: XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...)\n",
      "max_depth: [5]\n",
      "learning_rate: [0.20755617]\n",
      "n_estimators: [120]\n",
      "subsample: [0.81864631]\n",
      "colsample_bytree: [0.92013176]\n",
      "gamma: [0.04134697]\n",
      "n_class: 2\n",
      "n_iter: 1 \n",
      "\n",
      "\n",
      "Accuracy: 0.5575418994413408\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.60      0.63      0.61       995\n",
      "         1.0       0.50      0.47      0.48       795\n",
      "\n",
      "    accuracy                           0.56      1790\n",
      "   macro avg       0.55      0.55      0.55      1790\n",
      "weighted avg       0.55      0.56      0.56      1790\n",
      "\n",
      "*********************************************************\n",
      "Running the model task with the following parameters:\n",
      "target: condition2\n",
      "model: XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...)\n",
      "max_depth: [7 8 7 5 8 4 7 9 6 4 7 9 7 6 6 3 7 5 9 3]\n",
      "learning_rate: [0.07751246 0.24241037 0.22177995 0.02803316 0.1483823  0.18003746\n",
      " 0.23425996 0.10140889 0.19132224 0.03330868 0.2858397  0.27884053\n",
      " 0.19182028 0.18627772 0.16805308 0.14722672 0.21460776 0.13306272\n",
      " 0.21543536 0.11231213]\n",
      "n_estimators: [155 105 191 148  55 109  64 167  70 107 195  90  85 141 186  84 184  72\n",
      " 157  61]\n",
      "subsample: [0.86088322 0.97135142 0.7639376  0.69875381 0.77067634 0.95357089\n",
      " 0.70190639 0.72013629 0.77606849 0.95132734 0.84405598 0.73736345\n",
      " 0.6311925  0.97875913 0.98746566 0.68385309 0.83686137 0.92896151\n",
      " 0.9529329  0.73407457]\n",
      "colsample_bytree: [0.58014514 0.69761948 0.76664762 0.78833011 0.62283791 0.52305964\n",
      " 0.6684493  0.72920082 0.72727987 0.79728458 0.82389422 0.7698165\n",
      " 0.90907205 0.53529171 0.71607077 0.74494307 0.7210693  0.82081651\n",
      " 0.84708239 0.51239361]\n",
      "gamma: [0.28050756 0.1508048  0.46571411 0.06709003 0.46149678 0.32212305\n",
      " 0.41864366 0.47067487 0.065548   0.05222419 0.27532549 0.30898744\n",
      " 0.42132088 0.32946282 0.23347323 0.20891651 0.21624064 0.35062965\n",
      " 0.11830415 0.43980594]\n",
      "n_class: 2\n",
      "n_iter: 20 \n",
      "\n",
      "\n",
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "Accuracy: 0.5731843575418994\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.59      0.75      0.66       995\n",
      "         1.0       0.53      0.36      0.43       795\n",
      "\n",
      "    accuracy                           0.57      1790\n",
      "   macro avg       0.56      0.55      0.54      1790\n",
      "weighted avg       0.56      0.57      0.56      1790\n",
      "\n",
      "\n",
      "Best Parameters:\n",
      " {'colsample_bytree': 0.6467440873590191, 'gamma': 0.007039911357542228, 'learning_rate': 0.06965272122664154, 'max_depth': 5, 'n_estimators': 82, 'subsample': 0.8423839899124046}\n"
     ]
    }
   ],
   "source": [
    "model_data(df=df2, target='condition2', model = xgb.XGBClassifier(), param_dist= param_grid_xgb,n_iter=1)\n",
    "model_data(df=df2, target='condition2', model = xgb.XGBClassifier(), param_dist= param_grid_xgb,n_iter=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "db899812-11bf-48a8-9624-4e454df7bd98",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************************************************\n",
      "Running the model task with the following parameters:\n",
      "target: condition2\n",
      "model: RandomForestClassifier()\n",
      "n_estimators: [170]\n",
      "max_depth: [6]\n",
      "min_samples_split: [2]\n",
      "min_samples_leaf: [3]\n",
      "n_class: 2\n",
      "n_iter: 1 \n",
      "\n",
      "\n",
      "Accuracy: 0.5670391061452514\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.59      0.74      0.66       995\n",
      "         1.0       0.52      0.35      0.42       795\n",
      "\n",
      "    accuracy                           0.57      1790\n",
      "   macro avg       0.55      0.55      0.54      1790\n",
      "weighted avg       0.56      0.57      0.55      1790\n",
      "\n",
      "*********************************************************\n",
      "Running the model task with the following parameters:\n",
      "target: condition2\n",
      "model: RandomForestClassifier()\n",
      "n_estimators: [188 142 185 198 167 112 116 137 182  51  94 128  85 131 198 133 136 137\n",
      " 177 109]\n",
      "max_depth: [9 6 6 7 8 4 8 5 6 8 6 7 9 6 3 5 5 8 5 9]\n",
      "min_samples_split: [9 2 4 4 7 8 9 5 6 8 7 6 7 4 7 5 9 2 7 6]\n",
      "min_samples_leaf: [6 1 5 6 3 9 5 4 3 1 9 3 6 9 7 2 4 9 5 5]\n",
      "n_class: 2\n",
      "n_iter: 20 \n",
      "\n",
      "\n",
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "Accuracy: 0.5558659217877095\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.56      1.00      0.71       995\n",
      "         1.0       0.00      0.00      0.00       795\n",
      "\n",
      "    accuracy                           0.56      1790\n",
      "   macro avg       0.28      0.50      0.36      1790\n",
      "weighted avg       0.31      0.56      0.40      1790\n",
      "\n",
      "\n",
      "Best Parameters:\n",
      " {'max_depth': 9, 'min_samples_leaf': 5, 'min_samples_split': 2, 'n_estimators': 67}\n"
     ]
    }
   ],
   "source": [
    "model_data(df=df2, target='condition2', model = RandomForestClassifier(), param_dist= param_grid_rf,n_iter=1)\n",
    "model_data(df=df2, target='condition2', model = RandomForestClassifier(), param_dist= param_grid_rf,n_iter=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "30d4d344-5c91-4887-9256-0a27275bfe56",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************************************************\n",
      "Running the model task with the following parameters:\n",
      "target: condition2\n",
      "model: AdaBoostClassifier()\n",
      "n_estimators: [128]\n",
      "learning_rate: [0.44334881]\n",
      "n_class: 2\n",
      "n_iter: 1 \n",
      "\n",
      "\n",
      "Accuracy: 0.5581005586592179\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.59      0.68      0.63       995\n",
      "         1.0       0.50      0.41      0.45       795\n",
      "\n",
      "    accuracy                           0.56      1790\n",
      "   macro avg       0.55      0.54      0.54      1790\n",
      "weighted avg       0.55      0.56      0.55      1790\n",
      "\n",
      "*********************************************************\n",
      "Running the model task with the following parameters:\n",
      "target: condition2\n",
      "model: AdaBoostClassifier()\n",
      "n_estimators: [138 181 198 142 159  96 173 132  82 114 142 104  72 118  86 104 145 185\n",
      "  69 180]\n",
      "learning_rate: [0.0481674  0.74673022 0.73468902 0.79119016 0.97752093 0.91556906\n",
      " 0.80633824 0.12429105 0.37839472 0.63272452 0.78384248 0.29454609\n",
      " 0.43938222 0.45488605 0.97753199 0.57513231 0.68689473 0.95032965\n",
      " 0.26004123 0.72422191]\n",
      "n_class: 2\n",
      "n_iter: 20 \n",
      "\n",
      "\n",
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "Accuracy: 0.5664804469273743\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.58      0.83      0.68       995\n",
      "         1.0       0.53      0.24      0.33       795\n",
      "\n",
      "    accuracy                           0.57      1790\n",
      "   macro avg       0.55      0.53      0.50      1790\n",
      "weighted avg       0.55      0.57      0.52      1790\n",
      "\n",
      "\n",
      "Best Parameters:\n",
      " {'learning_rate': 0.1934347898661638, 'n_estimators': 121}\n"
     ]
    }
   ],
   "source": [
    "model_data(df=df2, target='condition2', model = AdaBoostClassifier(), param_dist= param_grid_ab,n_iter=1)\n",
    "model_data(df=df2, target='condition2', model = AdaBoostClassifier(), param_dist= param_grid_ab,n_iter=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "853f5314-d946-4bd1-aff1-40d6e35fc047",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************************************************\n",
      "Running the model task with the following parameters:\n",
      "target: condition2\n",
      "model: SGDClassifier()\n",
      "alpha: [0.0001, 0.001, 0.01, 0.1]\n",
      "max_iter: [2384]\n",
      "tol: [0.001]\n",
      "penalty: ['l2', 'l1', 'elasticnet']\n",
      "n_class: 2\n",
      "n_iter: 1 \n",
      "\n",
      "\n",
      "Accuracy: 0.523463687150838\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.57      0.61      0.59       995\n",
      "         1.0       0.46      0.42      0.44       795\n",
      "\n",
      "    accuracy                           0.52      1790\n",
      "   macro avg       0.51      0.51      0.51      1790\n",
      "weighted avg       0.52      0.52      0.52      1790\n",
      "\n",
      "*********************************************************\n",
      "Running the model task with the following parameters:\n",
      "target: condition2\n",
      "model: SGDClassifier()\n",
      "alpha: [0.0001, 0.001, 0.01, 0.1]\n",
      "max_iter: [4776 9171 6665 7471 7548 6797 8341 5777 6355 2468 9838 9575 2214 9210\n",
      " 8117 1164 8353 2561 1432 9227]\n",
      "tol: [0.001]\n",
      "penalty: ['l2', 'l1', 'elasticnet']\n",
      "n_class: 2\n",
      "n_iter: 20 \n",
      "\n",
      "\n",
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "Accuracy: 0.5608938547486033\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.56      0.97      0.71       995\n",
      "         1.0       0.56      0.05      0.10       795\n",
      "\n",
      "    accuracy                           0.56      1790\n",
      "   macro avg       0.56      0.51      0.40      1790\n",
      "weighted avg       0.56      0.56      0.44      1790\n",
      "\n",
      "\n",
      "Best Parameters:\n",
      " {'alpha': 0.1, 'max_iter': 1775, 'penalty': 'elasticnet', 'tol': 0.001}\n"
     ]
    }
   ],
   "source": [
    "model_data(df=df2, target='condition2', model = SGDClassifier(), param_dist= param_grid_sgd,n_iter=1)\n",
    "model_data(df=df2, target='condition2', model = SGDClassifier(), param_dist= param_grid_sgd,n_iter=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f352b7ec-9c11-4107-828a-199188c11ce3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************************************************\n",
      "Running the model task with the following parameters:\n",
      "target: condition2\n",
      "model: KNeighborsClassifier()\n",
      "n_neighbors: [16]\n",
      "weights: ['uniform', 'distance']\n",
      "algorithm: ['ball_tree', 'kd_tree', 'brute']\n",
      "n_class: 2\n",
      "n_iter: 1 \n",
      "\n",
      "\n",
      "Accuracy: 0.523463687150838\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.57      0.58      0.57       995\n",
      "         1.0       0.46      0.46      0.46       795\n",
      "\n",
      "    accuracy                           0.52      1790\n",
      "   macro avg       0.52      0.52      0.52      1790\n",
      "weighted avg       0.52      0.52      0.52      1790\n",
      "\n",
      "*********************************************************\n",
      "Running the model task with the following parameters:\n",
      "target: condition2\n",
      "model: KNeighborsClassifier()\n",
      "n_neighbors: [15  9 21  7  9 27 25 11  9 16  6 24 27 29 22 23 17 10  7 25]\n",
      "weights: ['uniform', 'distance']\n",
      "algorithm: ['ball_tree', 'kd_tree', 'brute']\n",
      "n_class: 2\n",
      "n_iter: 20 \n",
      "\n",
      "\n",
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "Accuracy: 0.5569832402234637\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.59      0.70      0.64       995\n",
      "         1.0       0.50      0.38      0.43       795\n",
      "\n",
      "    accuracy                           0.56      1790\n",
      "   macro avg       0.54      0.54      0.54      1790\n",
      "weighted avg       0.55      0.56      0.55      1790\n",
      "\n",
      "\n",
      "Best Parameters:\n",
      " {'algorithm': 'kd_tree', 'n_neighbors': 24, 'weights': 'uniform'}\n"
     ]
    }
   ],
   "source": [
    "model_data(df=df2, target='condition2', model = KNeighborsClassifier(), param_dist= param_grid_knn,n_iter=1)\n",
    "model_data(df=df2, target='condition2', model = KNeighborsClassifier(), param_dist= param_grid_knn,n_iter=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d61441-7a49-4863-a126-14f3db809909",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************************************************\n",
      "Running the model task with the following parameters:\n",
      "target: condition2\n",
      "model: GaussianNB()\n",
      "n_class: 2\n",
      "n_iter: 1 \n",
      "\n",
      "\n",
      "Accuracy: 0.4480446927374302\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.77      0.01      0.02       995\n",
      "         1.0       0.45      1.00      0.62       795\n",
      "\n",
      "    accuracy                           0.45      1790\n",
      "   macro avg       0.61      0.50      0.32      1790\n",
      "weighted avg       0.63      0.45      0.28      1790\n",
      "\n",
      "*********************************************************\n",
      "Running the model task with the following parameters:\n",
      "target: condition2\n",
      "model: GaussianNB()\n",
      "n_class: 2\n",
      "n_iter: 20 \n",
      "\n",
      "\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Accuracy: 0.4480446927374302\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.77      0.01      0.02       995\n",
      "         1.0       0.45      1.00      0.62       795\n",
      "\n",
      "    accuracy                           0.45      1790\n",
      "   macro avg       0.61      0.50      0.32      1790\n",
      "weighted avg       0.63      0.45      0.28      1790\n",
      "\n",
      "\n",
      "Best Parameters:\n",
      " {}\n"
     ]
    }
   ],
   "source": [
    "model_data(df=df2, target='condition2', model = GaussianNB(), param_dist= param_grid_nb,n_iter=1)\n",
    "model_data(df=df2, target='condition2', model = GaussianNB(), param_dist= param_grid_nb,n_iter=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4a1e0c-6276-4441-a24d-ddf32e459a5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f8d973-197e-496e-8eec-809712d7d41a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086b6bf1-00c0-4aec-a519-3118c7737b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data(df=df1, target='condition1', model = GaussianNB(), param_dist= param_grid_nb,n_iter=100)\n",
    "\n",
    "model_data(df=df2, target='condition2', model = GaussianNB(), param_dist= param_grid_nb,n_iter=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746e4b30-6bb7-4404-934c-3fa368ab4dcb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28005f0f-f745-49db-88ca-bde7a38a077a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3e39b1-edae-4c6f-b59a-6a513caa88c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fcf34d73-b202-4e59-8175-9d34a29fbb7f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************************************************\n",
      "Running the model task with the following parameters:\n",
      "target: condition1\n",
      "model: XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...)\n",
      "max_depth: [5 6 9 9 9 5 4 4 5 6 7 4 6 6 6 4 8 3 8 9 7 4 3 5 8 4 6 4 6 4 8 8 4 4 4 7 6\n",
      " 3 9 3 6 8 9 8 5 8 8 4 7 6 7 6 8 4 6 3 4 8 5 6 8 7 9 4 5 7 9 9 5 8 9 7 5 7\n",
      " 3 9 5 4 6 8 7 6 3 8 6 4 8 9 4 4 9 6 9 8 5 8 6 3 3 4]\n",
      "learning_rate: [0.17459556 0.01108043 0.24613274 0.07717514 0.12532844 0.0551152\n",
      " 0.20439366 0.27499597 0.30282772 0.07841011 0.03914276 0.23708311\n",
      " 0.14593666 0.11617614 0.06342162 0.04621065 0.26344395 0.28755719\n",
      " 0.28083335 0.21310287 0.12752868 0.25363208 0.02970063 0.21517223\n",
      " 0.12120015 0.16156285 0.0671423  0.05170831 0.30882759 0.0924307\n",
      " 0.20298336 0.1688288  0.23329622 0.2173355  0.14573367 0.2409594\n",
      " 0.13201031 0.09969749 0.11733269 0.04654994 0.14411972 0.12908615\n",
      " 0.23838761 0.24817563 0.29975149 0.04485372 0.22792989 0.30980267\n",
      " 0.30823772 0.24176466 0.13528167 0.03255486 0.06314279 0.15496213\n",
      " 0.29950571 0.25125027 0.04491512 0.26408075 0.04979187 0.20528077\n",
      " 0.29025502 0.04963462 0.18438685 0.13836726 0.21625855 0.15025261\n",
      " 0.2495403  0.24725703 0.13196792 0.06374506 0.2821921  0.30662323\n",
      " 0.30564017 0.19612467 0.1369243  0.10050391 0.15938197 0.2190688\n",
      " 0.03815783 0.19946798 0.28091043 0.19532762 0.20618738 0.24416716\n",
      " 0.18989984 0.11024242 0.29162102 0.2360923  0.2354236  0.01944326\n",
      " 0.25450129 0.01920693 0.01709664 0.23095188 0.21635723 0.274716\n",
      " 0.109771   0.10413939 0.03133461 0.15950267]\n",
      "n_estimators: [ 74 156 103 152 131 194 185 187 118 150 127  63 100 160 145 136 190 147\n",
      "  76 179 193 199  88  92 136 132 153 149 132 103 128  74 183 160  59 188\n",
      " 102 196 141 172 158 133 140 186 192  71  95  59  92  72 145  82 154 199\n",
      " 130 150  90 147 186 186 109 132  53  74  72  84 143 146 112 147 117 144\n",
      " 109 121 134  57  50 172  57 193 133  76 111  77 175 164 115 159  87 132\n",
      "  79  58 181 111  66  54 168 188  54  77]\n",
      "subsample: [0.81014238 0.87855785 0.79555226 0.81545868 0.71470274 0.97912532\n",
      " 0.99942228 0.69911168 0.66714033 0.60861862 0.7263295  0.94589187\n",
      " 0.77919808 0.62997908 0.89696167 0.8688505  0.82772206 0.8976377\n",
      " 0.73928289 0.84918809 0.70959967 0.66357602 0.62802745 0.83899722\n",
      " 0.8840883  0.96791863 0.85860009 0.92397444 0.83961525 0.7068\n",
      " 0.77029641 0.96842749 0.89945407 0.6294517  0.61932887 0.76731987\n",
      " 0.73093242 0.64017883 0.90529873 0.96551803 0.66147268 0.62320543\n",
      " 0.82644873 0.67671428 0.96900314 0.99601593 0.99551941 0.6238911\n",
      " 0.66200106 0.95975149 0.75678938 0.95601985 0.79285991 0.78731622\n",
      " 0.61117301 0.66055148 0.82399092 0.63449146 0.66486585 0.7334496\n",
      " 0.83817195 0.67404308 0.6904135  0.98360419 0.83664125 0.81216545\n",
      " 0.90264014 0.81955384 0.60400728 0.86298294 0.82458051 0.69617204\n",
      " 0.80983959 0.92886454 0.90839057 0.83296633 0.6414279  0.88957234\n",
      " 0.65003309 0.92673187 0.89244416 0.80962238 0.83066134 0.74561175\n",
      " 0.82151055 0.79253129 0.75620759 0.77684127 0.97544527 0.97681637\n",
      " 0.8278619  0.99678237 0.82988686 0.80837091 0.75682693 0.73371734\n",
      " 0.64888935 0.72052185 0.98828789 0.69458469]\n",
      "colsample_bytree: [0.90646163 0.92601585 0.66340118 0.50092655 0.93947082 0.84758205\n",
      " 0.79519047 0.76617028 0.73591617 0.61689064 0.98680261 0.51337074\n",
      " 0.77795274 0.51261627 0.78176308 0.90803675 0.96173534 0.88762883\n",
      " 0.57585314 0.67234388 0.891181   0.54779464 0.71111135 0.73013774\n",
      " 0.6814472  0.85784849 0.64913077 0.90465495 0.70575905 0.85312226\n",
      " 0.63860467 0.7745257  0.80273247 0.68856793 0.75618977 0.64389873\n",
      " 0.54581545 0.63336628 0.58236779 0.99501938 0.91728935 0.79368251\n",
      " 0.96947342 0.88280492 0.82808026 0.80384201 0.94351066 0.81925434\n",
      " 0.56848367 0.82308084 0.63306588 0.85338081 0.66438172 0.5902476\n",
      " 0.53044172 0.77215439 0.98328536 0.5672006  0.88912173 0.58142849\n",
      " 0.9446     0.54607166 0.71773119 0.78692855 0.76620648 0.75801537\n",
      " 0.70058587 0.87726871 0.56038608 0.74357431 0.7935273  0.98504786\n",
      " 0.60296627 0.84843254 0.5952297  0.55596181 0.7172973  0.73422353\n",
      " 0.84630944 0.77000273 0.56656254 0.9048099  0.66785225 0.77871113\n",
      " 0.82775653 0.86186901 0.7091239  0.94162318 0.68589717 0.60115931\n",
      " 0.70217181 0.73675451 0.79863929 0.88933504 0.56825908 0.63035556\n",
      " 0.93390715 0.51796808 0.70354721 0.52486987]\n",
      "gamma: [0.23787874 0.25140326 0.25231223 0.26256931 0.19672382 0.08190489\n",
      " 0.20986629 0.0319349  0.29233759 0.44233473 0.31105065 0.25474059\n",
      " 0.08379262 0.20882684 0.15332772 0.03206224 0.05457823 0.20099239\n",
      " 0.10797814 0.29375595 0.25961637 0.34110095 0.00348182 0.04023373\n",
      " 0.49975233 0.23352968 0.13909987 0.23778711 0.26288747 0.41872936\n",
      " 0.27224371 0.12241197 0.44788929 0.02664886 0.15470891 0.21000036\n",
      " 0.12884976 0.14723718 0.08842409 0.49529703 0.25701432 0.4275412\n",
      " 0.22171719 0.28429596 0.432718   0.49148428 0.03523556 0.4898328\n",
      " 0.38586509 0.41323344 0.08852273 0.0682693  0.10404747 0.3415383\n",
      " 0.40093814 0.31385478 0.34800389 0.40561084 0.12215612 0.41923003\n",
      " 0.23802695 0.07354505 0.13960647 0.02763212 0.25192048 0.08497359\n",
      " 0.24748216 0.32957631 0.23623267 0.08610852 0.17557231 0.00341348\n",
      " 0.42447826 0.23520347 0.31487398 0.05592765 0.42721056 0.07954964\n",
      " 0.2481703  0.14150608 0.01179264 0.05942054 0.23750349 0.30063982\n",
      " 0.05733687 0.0815817  0.01021814 0.34602969 0.42781323 0.27678508\n",
      " 0.07711808 0.30116751 0.068217   0.16001123 0.40126568 0.11013521\n",
      " 0.32829121 0.15533073 0.09241699 0.09104986]\n",
      "n_class: 2\n",
      "n_iter: 100 \n",
      "\n",
      "\n",
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n",
      "Accuracy: 0.5968096809680968\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.60      0.75      0.67       981\n",
      "         1.0       0.59      0.42      0.49       837\n",
      "\n",
      "    accuracy                           0.60      1818\n",
      "   macro avg       0.59      0.58      0.58      1818\n",
      "weighted avg       0.59      0.60      0.59      1818\n",
      "\n",
      "\n",
      "Best Parameters:\n",
      " {'colsample_bytree': 0.6557066546956472, 'gamma': 0.4897552643107543, 'learning_rate': 0.06259908096680156, 'max_depth': 4, 'n_estimators': 134, 'subsample': 0.7893887083122263}\n"
     ]
    }
   ],
   "source": [
    "model_data(df=df1, target='condition1', model = xgb.XGBClassifier(), param_dist= param_grid_xgb,n_iter=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d039b7a5-e568-478f-a720-9d11ac878fc1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************************************************\n",
      "Running the model task with the following parameters:\n",
      "target: condition1\n",
      "model: RandomForestClassifier()\n",
      "n_estimators: [153 181  54 193 186 151  86 120  89  72 128  83  66 113 195  84  77 123\n",
      " 197 164 121  86 191  73  68  80 193 158 157  73  61 187 153 127 181  52\n",
      " 101 116 187  59 193 192 160 177 126 117  81 173 177  83 163 185 144 196\n",
      " 106  60 104  74 165 112  57  98 109 151 122 124  92 106 177  61  75  66\n",
      "  83 185 143 150  63  64  85  95  80  92 184 118  88 101 148  74 152  57\n",
      " 107 135  94 102 197  75 186 147 113  53]\n",
      "max_depth: [6 9 3 8 3 8 7 6 5 6 4 3 4 6 3 9 9 4 8 9 7 3 9 5 5 4 4 6 5 5 9 9 3 9 6 6 9\n",
      " 7 7 7 9 5 5 7 4 6 7 4 9 3 4 3 9 9 4 8 9 9 9 5 4 9 8 9 5 4 3 8 6 3 5 5 4 6\n",
      " 7 6 9 9 9 5 3 4 5 3 3 9 6 4 4 5 3 7 9 5 5 7 7 8 8 6]\n",
      "min_samples_split: [6 5 8 8 9 4 9 5 5 7 4 4 2 6 8 7 7 8 9 5 2 8 5 5 3 9 3 7 8 3 3 3 6 2 7 4 9\n",
      " 3 7 4 9 3 5 5 4 6 6 2 5 5 2 3 7 5 5 8 3 2 6 8 9 8 8 7 9 4 3 4 3 8 4 9 4 2\n",
      " 5 2 7 7 8 9 2 6 7 9 8 8 4 4 7 6 3 7 4 5 7 4 2 4 8 3]\n",
      "min_samples_leaf: [8 9 4 2 2 3 4 2 1 6 3 9 3 7 9 9 8 9 1 8 8 9 1 5 3 5 7 9 4 2 8 5 5 6 3 8 2\n",
      " 7 2 6 5 3 2 7 6 3 2 5 6 8 2 4 4 8 9 6 6 6 6 2 5 4 7 6 2 5 7 2 5 2 3 5 8 1\n",
      " 5 5 7 4 7 8 4 3 1 7 1 3 9 3 8 4 4 6 9 6 1 2 1 9 5 2]\n",
      "n_class: 2\n",
      "n_iter: 100 \n",
      "\n",
      "\n",
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n",
      "Accuracy: 0.583058305830583\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.58      0.84      0.69       981\n",
      "         1.0       0.60      0.28      0.38       837\n",
      "\n",
      "    accuracy                           0.58      1818\n",
      "   macro avg       0.59      0.56      0.53      1818\n",
      "weighted avg       0.59      0.58      0.55      1818\n",
      "\n",
      "\n",
      "Best Parameters:\n",
      " {'max_depth': 9, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 145}\n"
     ]
    }
   ],
   "source": [
    "model_data(df=df1, target='condition1', model = RandomForestClassifier(), param_dist= param_grid_rf,n_iter=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78c9d151-daf4-4abd-a9f0-524e134f95d8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************************************************\n",
      "Running the model task with the following parameters:\n",
      "target: condition1\n",
      "model: AdaBoostClassifier()\n",
      "n_estimators: [ 72 117  93 193  91 104 106 194 102 115  60 146 174 159  91 113  87 142\n",
      " 104 116  51 169  87 145 102 135 169  52  84 193 136 184 109  75 115 120\n",
      " 107  55  70  54 181 187 177 172  57  69 175 125  65  83  90 142 175 142\n",
      " 135 155 119 131 148 166 199  87  65  99 196 108  96 134  81  58 117  93\n",
      "  73 156  65 139 149 121  61 168 144  54 163 102 106  91  69  96 124 155\n",
      "  71  58 136  52 106 191 140 199 129 180]\n",
      "learning_rate: [0.20636272 0.44173392 0.16736606 0.98030113 0.36545323 0.17749219\n",
      " 0.87369731 0.50438042 0.92872831 0.91649096 0.66060408 0.75431055\n",
      " 0.05741713 0.58092712 0.38963839 0.25348176 0.51971293 0.79665165\n",
      " 0.16585512 0.06332597 0.99799928 0.17602281 0.55201054 0.31159025\n",
      " 0.80759166 0.55439478 0.7466375  0.13737021 0.30361912 0.11873342\n",
      " 0.08532153 0.90645571 0.52621401 0.28016723 0.99927449 0.44093058\n",
      " 0.71376343 0.34440885 0.80817499 0.55055672 0.31967318 0.04977501\n",
      " 0.36605024 0.08074141 0.62605891 0.23117342 0.58429655 0.09777247\n",
      " 0.34386866 0.21279305 0.21991434 0.87889393 0.24558633 0.8350424\n",
      " 0.76990457 0.67453451 0.70097101 0.91984815 0.12843377 0.07603498\n",
      " 0.71015397 0.88973005 0.18350384 0.1804905  0.81527044 0.90835992\n",
      " 0.66536879 0.92913017 0.07963436 0.19877401 0.29400372 0.57777482\n",
      " 0.48370981 0.16315702 0.91640154 0.11075442 0.40110952 0.8565531\n",
      " 0.68966835 0.40661996 0.40233311 0.96256069 0.30256464 0.97204524\n",
      " 0.48577594 0.48893885 0.21814827 0.0441588  1.00510709 0.92008668\n",
      " 0.33811502 0.27985285 0.01769842 0.73703661 0.59069552 0.80207783\n",
      " 0.61220877 0.39489269 0.74384378 0.85909114]\n",
      "n_class: 2\n",
      "n_iter: 100 \n",
      "\n",
      "\n",
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n",
      "Accuracy: 0.6028602860286029\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.60      0.76      0.68       981\n",
      "         1.0       0.60      0.41      0.49       837\n",
      "\n",
      "    accuracy                           0.60      1818\n",
      "   macro avg       0.60      0.59      0.58      1818\n",
      "weighted avg       0.60      0.60      0.59      1818\n",
      "\n",
      "\n",
      "Best Parameters:\n",
      " {'learning_rate': 0.4098609717152555, 'n_estimators': 64}\n"
     ]
    }
   ],
   "source": [
    "model_data(df=df1, target='condition1', model = AdaBoostClassifier(), param_dist= param_grid_ab,n_iter=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "710a4821-8912-4a14-a5cc-6acf0a145d6d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************************************************\n",
      "Running the model task with the following parameters:\n",
      "target: condition1\n",
      "model: SGDClassifier()\n",
      "alpha: [0.0001, 0.001, 0.01, 0.1]\n",
      "max_iter: [8339 6782 8878 4234 4854 1985 7622 9400 3690 2821 1266 5698 8863 6797\n",
      " 6635 7165 6099 4237 1816 3476 4726 5505 4795 9772 5339 3330 7709 7556\n",
      " 8559 1614 1827 4641 9708 6206 8746 6286 8719 6419 2636 8343 1581 6255\n",
      " 5953 8202 5450 1870 9248 2622 8021 2814 5561 3965 6982 5728 1637 2322\n",
      " 8093 9432 6376 8702 2141 6475 5111 7284 3901 3825 5070 5981 8687 5989\n",
      " 7408 7437 6288 3855 6879 2207 1234 1743 8367 5409 4868 4098 5818 5394\n",
      " 6660 4772 4574 6019 3096 2156 9298 5315 9595 1781 8142 2831 3929 3563\n",
      " 3978 2890]\n",
      "tol: [0.001]\n",
      "penalty: ['l2', 'l1', 'elasticnet']\n",
      "n_class: 2\n",
      "n_iter: 100 \n",
      "\n",
      "\n",
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n",
      "Accuracy: 0.5775577557755776\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.57      0.90      0.70       981\n",
      "         1.0       0.63      0.20      0.30       837\n",
      "\n",
      "    accuracy                           0.58      1818\n",
      "   macro avg       0.60      0.55      0.50      1818\n",
      "weighted avg       0.60      0.58      0.52      1818\n",
      "\n",
      "\n",
      "Best Parameters:\n",
      " {'alpha': 0.1, 'max_iter': 8158, 'penalty': 'l2', 'tol': 0.001}\n"
     ]
    }
   ],
   "source": [
    "model_data(df=df1, target='condition1', model = SGDClassifier(), param_dist= param_grid_sgd,n_iter=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "def2c1b4-d458-4d1c-b7a6-8a0b4baf42bf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************************************************\n",
      "Running the model task with the following parameters:\n",
      "target: condition1\n",
      "model: KNeighborsClassifier()\n",
      "n_neighbors: [11  7  7 18 17 27 25 18 19 24  6 19  3  7 16  4 13 14 10  6  9 11 11  9\n",
      " 16 22  7 26 18 20  6  5  5 20  8  6 13 16  4 20 29  8 20 14  4 25 25 14\n",
      " 27 17 26 19 27  8  3 19 23 10 12  8 23 26 24  5  7 18 26 25 27 21 21 10\n",
      "  4 22  3 27 18 20 19 11 22 19 13  3 25  3 24 11 21 13 28 10 24 22 26 16\n",
      " 10 27 19 29]\n",
      "weights: ['uniform', 'distance']\n",
      "algorithm: ['ball_tree', 'kd_tree', 'brute']\n",
      "n_class: 2\n",
      "n_iter: 100 \n",
      "\n",
      "\n",
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n",
      "Accuracy: 0.5841584158415841\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.59      0.72      0.65       981\n",
      "         1.0       0.57      0.42      0.48       837\n",
      "\n",
      "    accuracy                           0.58      1818\n",
      "   macro avg       0.58      0.57      0.57      1818\n",
      "weighted avg       0.58      0.58      0.57      1818\n",
      "\n",
      "\n",
      "Best Parameters:\n",
      " {'algorithm': 'brute', 'n_neighbors': 28, 'weights': 'distance'}\n"
     ]
    }
   ],
   "source": [
    "model_data(df=df1, target='condition1', model = KNeighborsClassifier(), param_dist= param_grid_knn,n_iter=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7a5a2cd3-a49d-41fb-944f-9316f6bb3479",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************************************************\n",
      "Running the model task with the following parameters:\n",
      "target: condition1\n",
      "model: GaussianNB()\n",
      "n_class: 2\n",
      "n_iter: 100 \n",
      "\n",
      "\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Accuracy: 0.45764576457645767\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       981\n",
      "         1.0       0.46      0.99      0.63       837\n",
      "\n",
      "    accuracy                           0.46      1818\n",
      "   macro avg       0.23      0.50      0.31      1818\n",
      "weighted avg       0.21      0.46      0.29      1818\n",
      "\n",
      "\n",
      "Best Parameters:\n",
      " {}\n"
     ]
    }
   ],
   "source": [
    "model_data(df=df1, target='condition1', model = GaussianNB(), param_dist= param_grid_nb,n_iter=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17cc0a20-fb61-433d-82d1-a5d8ec54a98b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************************************************\n",
      "Running the model task with the following parameters:\n",
      "target: condition2\n",
      "model: XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...)\n",
      "max_depth: [9 3 7 3 6 3 6 5 3 4 9 8 7 5 9 8 4 7 3 9 7 4 7 9 6 6 8 3 3 8 7 6 8 3 3 7 4\n",
      " 7 6 4 8 7 7 8 7 8 6 9 3 7 4 5 8 3 6 8 6 6 6 8 7 4 5 3 3 5 8 8 9 7 9 5 8 8\n",
      " 7 7 3 7 8 7 6 6 3 8 6 7 5 4 9 7 9 6 4 6 5 5 7 9 5 7]\n",
      "learning_rate: [0.25504866 0.16050654 0.1024629  0.12554101 0.20791613 0.23203161\n",
      " 0.20302001 0.02339622 0.0996398  0.30046679 0.21277625 0.17345301\n",
      " 0.28093496 0.04337048 0.27772096 0.25743282 0.11007974 0.14548601\n",
      " 0.15333184 0.09574073 0.06735941 0.23228062 0.12922942 0.2038079\n",
      " 0.19685588 0.13603049 0.05787114 0.01218489 0.12783697 0.03317497\n",
      " 0.19646746 0.30444854 0.20622635 0.04434823 0.22360982 0.10521873\n",
      " 0.19133902 0.28397852 0.04290853 0.24705452 0.14035133 0.2211932\n",
      " 0.27441628 0.07675342 0.05676672 0.02679907 0.15904087 0.10408235\n",
      " 0.19940995 0.30901573 0.27948498 0.02455035 0.03347632 0.16138159\n",
      " 0.29644758 0.1925923  0.14550948 0.19251502 0.30052192 0.25848052\n",
      " 0.07588919 0.02054605 0.08116944 0.06183487 0.21209014 0.15838422\n",
      " 0.22504514 0.30548826 0.12317771 0.14252868 0.20667642 0.14984621\n",
      " 0.11344697 0.0538822  0.15503486 0.01977668 0.16128453 0.16498752\n",
      " 0.21663332 0.05441701 0.05233827 0.0138552  0.05351367 0.10165985\n",
      " 0.09160731 0.02854187 0.26605811 0.21045439 0.02331039 0.23929375\n",
      " 0.12486606 0.24778838 0.30295801 0.19374008 0.1603959  0.25746365\n",
      " 0.0671063  0.20515715 0.10604462 0.03258458]\n",
      "n_estimators: [133 120  78 188 138 136  51 148  50 111 188  58 138  50 123  75  89 135\n",
      "  70 139 105 121 150  59  82 109 189 144  84 173 161 172  68  57 110 197\n",
      " 180 193 196  52 194 139 191  83 137  79 145 102 145 165  74 128 111 100\n",
      " 143 108  90 198 178  61 142 125  56  77 171 166 145  66 125  68 179 104\n",
      "  55  88 162 153 168  77 199 170 193  79  83 138 198 199  56  68 170 155\n",
      "  86 102 112 149 119 156 124 190 194  98]\n",
      "subsample: [0.81379052 0.84350882 0.6831906  0.99487628 0.62011423 0.70523312\n",
      " 0.99171216 0.75941153 0.94898833 0.95019016 0.72306482 0.80005413\n",
      " 0.9322344  0.95461418 0.70131536 0.93028201 0.89593095 0.60143646\n",
      " 0.72703551 0.70153919 0.96933052 0.93416398 0.81408802 0.72099394\n",
      " 0.62216747 0.62198712 0.64580187 0.69776639 0.79136578 0.6492918\n",
      " 0.71604082 0.97371367 0.87813958 0.84328665 0.81531603 0.81687522\n",
      " 0.79913662 0.86379719 0.93432375 0.62995936 0.91999403 0.66207628\n",
      " 0.71474232 0.7534891  0.79311505 0.91797306 0.96964904 0.92363946\n",
      " 0.95433974 0.98863694 0.88703285 0.61241466 0.87215406 0.65653154\n",
      " 0.75877327 0.60952948 0.84840584 0.60723454 0.75579258 0.88937774\n",
      " 0.8765555  0.89314757 0.7836023  0.87554166 0.63685388 0.8447551\n",
      " 0.79382808 0.9582303  0.94575454 0.71670367 0.91846245 0.68248469\n",
      " 0.63223367 0.65249857 0.95283557 0.67044922 0.71572296 0.96819026\n",
      " 0.81220575 0.73397625 0.87356556 0.80142106 0.61865157 0.84643023\n",
      " 0.99051871 0.65509381 0.85310908 0.75873243 0.83073799 0.7768775\n",
      " 0.77436592 0.63999135 0.86277543 0.63470832 0.60895405 0.94769206\n",
      " 0.92099605 0.65436746 0.67685173 0.61527931]\n",
      "colsample_bytree: [0.80764504 0.66117458 0.86724652 0.66411395 0.59619536 0.65378359\n",
      " 0.92061883 0.56206593 0.58313355 0.90449456 0.55286464 0.64499053\n",
      " 0.90714229 0.75649917 0.8069787  0.84663909 0.55340443 0.6564641\n",
      " 0.56616981 0.84541186 0.94550393 0.97547344 0.97111491 0.9370621\n",
      " 0.65570361 0.85006383 0.86134018 0.6662254  0.97378452 0.99101974\n",
      " 0.76770509 0.88848062 0.90957609 0.66147567 0.78824487 0.91626516\n",
      " 0.54758537 0.65301608 0.60804686 0.56169752 0.53077393 0.80982778\n",
      " 0.88079263 0.91943857 0.7545518  0.66239025 0.69310208 0.8970623\n",
      " 0.50689475 0.53321293 0.62593495 0.52247019 0.72786157 0.6224384\n",
      " 0.54751503 0.79468182 0.66918366 0.71168188 0.57967068 0.63943042\n",
      " 0.72206497 0.56181144 0.73574565 0.88686194 0.76415643 0.86335603\n",
      " 0.59511939 0.79473108 0.98311554 0.62606785 0.62937493 0.69899605\n",
      " 0.691697   0.74540316 0.69830937 0.77377528 0.7734686  0.72909378\n",
      " 0.51442004 0.84996516 0.61411507 0.74178806 0.64910733 0.73222694\n",
      " 0.5285281  0.56794936 0.78802319 0.64997491 0.99868892 0.78474046\n",
      " 0.63785449 0.83602088 0.76204319 0.84514672 0.54314869 0.82006823\n",
      " 0.60445127 0.93909543 0.59928947 0.7279142 ]\n",
      "gamma: [0.10836428 0.04399508 0.24293998 0.0121212  0.3638995  0.48687726\n",
      " 0.29397055 0.05303025 0.01033478 0.38617562 0.40346162 0.14941341\n",
      " 0.38463339 0.33426303 0.04959501 0.35269566 0.12475729 0.4420009\n",
      " 0.07302904 0.105361   0.44918025 0.21916992 0.22898852 0.31353553\n",
      " 0.17265699 0.37954086 0.33565707 0.42117128 0.07448267 0.04781541\n",
      " 0.07620531 0.43553611 0.46088818 0.20444075 0.12987531 0.32475719\n",
      " 0.20959282 0.44760115 0.38317057 0.07097591 0.00890576 0.3526802\n",
      " 0.02815809 0.44894399 0.41782343 0.05797115 0.32237994 0.17804461\n",
      " 0.49163902 0.43240468 0.32876109 0.06551756 0.1239626  0.42507908\n",
      " 0.19841841 0.28736469 0.14775386 0.28604923 0.4811044  0.34281778\n",
      " 0.44453307 0.29993879 0.44118557 0.29754985 0.42174318 0.46727415\n",
      " 0.37605146 0.31637206 0.25006005 0.11741278 0.4494385  0.34699869\n",
      " 0.12810976 0.24751245 0.42362101 0.41698967 0.09891204 0.33828984\n",
      " 0.46525846 0.23641327 0.18001002 0.19105772 0.39470297 0.10118403\n",
      " 0.12888676 0.37449777 0.22193926 0.19046775 0.42094862 0.21475759\n",
      " 0.1163465  0.05822833 0.4082373  0.09193619 0.44086093 0.37194553\n",
      " 0.20674917 0.01460861 0.30366517 0.42657797]\n",
      "n_class: 2\n",
      "n_iter: 100 \n",
      "\n",
      "\n",
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n",
      "Accuracy: 0.5754189944134078\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.59      0.81      0.68       995\n",
      "         1.0       0.54      0.28      0.37       795\n",
      "\n",
      "    accuracy                           0.58      1790\n",
      "   macro avg       0.56      0.55      0.53      1790\n",
      "weighted avg       0.57      0.58      0.54      1790\n",
      "\n",
      "\n",
      "Best Parameters:\n",
      " {'colsample_bytree': 0.5056768223837096, 'gamma': 0.23433032099706314, 'learning_rate': 0.026890982704551203, 'max_depth': 6, 'n_estimators': 110, 'subsample': 0.9291161407506773}\n"
     ]
    }
   ],
   "source": [
    "model_data(df=df2, target='condition2', model = xgb.XGBClassifier(), param_dist= param_grid_xgb,n_iter=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68f503d-c6b9-4ce8-8aa3-d30f576f3f05",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************************************************\n",
      "Running the model task with the following parameters:\n",
      "target: condition2\n",
      "model: RandomForestClassifier()\n",
      "n_estimators: [122  86 154 126 199 176 148 161  77 164 180 117  51 128 122 185 117  65\n",
      " 158 130 106 115 129 150  96  56 166 154 126 130  94 113 108 170  54  66\n",
      "  95 179 109 124  90 168  81 136  82 186 198 192 138 137 104 116  51  50\n",
      " 184  65  88 101  65 114 170  66 153 117  58  83 168 184  70  50 159 157\n",
      "  70 195  62 148 172 149  77 136 197 149  62 175 161 195  56 121 173  78\n",
      " 105 138 134 125  67 199  97 195  58 103]\n",
      "max_depth: [4 6 8 7 4 4 7 9 7 7 5 6 7 4 9 7 6 4 4 6 7 9 4 8 9 4 8 8 8 3 4 6 8 8 8 5 8\n",
      " 8 7 6 3 9 5 3 6 9 4 8 6 5 5 8 9 8 4 9 9 4 6 3 6 9 7 8 8 4 4 8 3 6 7 7 7 6\n",
      " 3 4 6 6 8 3 6 4 7 9 8 3 3 8 6 6 6 6 7 8 7 5 7 8 9 5]\n",
      "min_samples_split: [3 7 9 7 7 8 8 6 2 5 8 8 8 3 8 8 6 4 8 9 5 6 4 2 6 2 4 7 6 3 7 5 4 7 6 6 9\n",
      " 7 2 8 7 6 4 8 7 4 2 7 8 4 9 6 9 2 9 7 6 5 5 3 4 7 8 2 5 7 3 9 9 2 5 2 7 2\n",
      " 4 8 7 4 3 5 7 9 9 4 2 3 9 3 9 2 4 5 3 9 5 7 9 5 4 8]\n",
      "min_samples_leaf: [3 8 9 3 4 2 6 3 1 6 3 9 1 9 9 9 6 8 1 4 8 9 1 6 3 8 2 6 3 5 5 2 3 2 3 8 8\n",
      " 7 4 8 2 7 6 5 9 1 3 8 4 8 5 6 8 1 9 4 2 6 5 1 8 4 1 6 9 3 1 1 8 1 5 9 7 2\n",
      " 8 3 5 2 2 7 7 9 7 4 5 7 8 4 3 5 8 5 2 2 9 6 1 5 8 9]\n",
      "n_class: 2\n",
      "n_iter: 100 \n",
      "\n",
      "\n",
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n",
      "Accuracy: 0.5569832402234637\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.56      1.00      0.71       995\n",
      "         1.0       0.75      0.00      0.01       795\n",
      "\n",
      "    accuracy                           0.56      1790\n",
      "   macro avg       0.65      0.50      0.36      1790\n",
      "weighted avg       0.64      0.56      0.40      1790\n",
      "\n",
      "\n",
      "Best Parameters:\n",
      " {'max_depth': 8, 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 101}\n"
     ]
    }
   ],
   "source": [
    "model_data(df=df2, target='condition2', model = RandomForestClassifier(), param_dist= param_grid_rf,n_iter=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a682c32-e4af-4833-9c27-de1ca6e7e42e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************************************************\n",
      "Running the model task with the following parameters:\n",
      "target: condition2\n",
      "model: AdaBoostClassifier()\n",
      "n_estimators: [ 56 141  50 180 142 185 142 198  80 140  76 108 154 175  88 155 123  65\n",
      " 123 105 143 161  73 127 180 192 151 148 147 176 187 150 116 198 181 184\n",
      " 122 149 156  84 177 168 184 147 167 133  80 186  56  52 105 138  90 170\n",
      " 130  74 148  76  77  90  79 191  50 192  60 123  91 132 192  74  83 140\n",
      " 148 171  84 192 171  74 104  95  73  76 133  75 112  52  62  81 136 170\n",
      " 161 102  97  81 183  66 188 102 130  55]\n",
      "learning_rate: [0.28951355 0.23118789 0.54570681 0.30515933 0.20422108 0.19115242\n",
      " 0.17324367 0.08935469 0.57783163 0.69727626 0.80037385 0.03368296\n",
      " 0.47202062 0.53119418 0.03440261 0.81018069 0.3212295  0.87690751\n",
      " 0.81205479 0.75028091 0.82305478 0.82968568 0.64547027 0.55672778\n",
      " 0.31254561 0.15502382 0.06504859 0.17394972 0.8396309  0.57657144\n",
      " 0.09678005 0.46721225 0.01591027 0.50325289 0.5310654  0.66660708\n",
      " 0.5858539  0.36954939 0.77300433 0.89578137 0.94856023 0.2313122\n",
      " 0.17505786 0.56646544 0.44125468 0.68895101 0.33466435 0.3342203\n",
      " 0.36239063 0.32797248 0.99205419 0.59804538 0.35281431 0.96358439\n",
      " 0.36736332 0.94879886 0.69234504 0.40566849 0.71088651 0.61333575\n",
      " 0.92930443 0.79268404 0.3354801  0.65913625 0.47969    0.31225992\n",
      " 0.87833123 0.26530278 0.03411728 0.33937188 0.20512374 0.40258129\n",
      " 0.0243908  0.72336245 0.5443532  0.60435815 0.27788368 0.39351496\n",
      " 0.51075633 0.16718929 0.88692159 0.6867366  0.72653862 0.22204775\n",
      " 0.52821704 0.83362073 0.74746054 0.6104771  0.55111753 0.34635608\n",
      " 0.3195579  0.23102871 0.24979227 0.45190522 1.00141526 0.48555969\n",
      " 0.97933262 0.22240808 0.62771099 0.63440131]\n",
      "n_class: 2\n",
      "n_iter: 100 \n",
      "\n",
      "\n",
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n",
      "Accuracy: 0.5631284916201117\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.57      0.83      0.68       995\n",
      "         1.0       0.52      0.23      0.32       795\n",
      "\n",
      "    accuracy                           0.56      1790\n",
      "   macro avg       0.55      0.53      0.50      1790\n",
      "weighted avg       0.55      0.56      0.52      1790\n",
      "\n",
      "\n",
      "Best Parameters:\n",
      " {'learning_rate': 0.1752669390630025, 'n_estimators': 138}\n"
     ]
    }
   ],
   "source": [
    "model_data(df=df2, target='condition2', model = AdaBoostClassifier(), param_dist= param_grid_ab,n_iter=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe2e049-e6d8-4723-a5bd-ede3795f87ba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************************************************\n",
      "Running the model task with the following parameters:\n",
      "target: condition2\n",
      "model: SGDClassifier()\n",
      "alpha: [0.0001, 0.001, 0.01, 0.1]\n",
      "max_iter: [3062 3569 6203 1152 6066 9592 8655 6753 7779 7354 3219 8714 7910 9639\n",
      " 7498 7649 7991 2024 5720 2736 5972 5069 5049 2898 1620 9691 4077 9067\n",
      " 8613 1475 8821 5408 3780 5217 2776 2554 6362 7074 4924 4378 4522 3024\n",
      " 5182 5442 5930 2358 4209 7050 8670 4754 4787 3805 8358 4654 8721 9149\n",
      " 4691 5335 1743 7080 9951 4976 6957 4458 8432 6259 4798 8750 8201 1239\n",
      " 3134 4355 7981 4495 5163 7875 3248 6183 2038 1398 3801 8933 5668 9148\n",
      " 5419 3221 9874 9422 8751 3652 1069 8512 4012 9222 5205 9048 2698 6741\n",
      " 6454 4925]\n",
      "tol: [0.001]\n",
      "penalty: ['l2', 'l1', 'elasticnet']\n",
      "n_class: 2\n",
      "n_iter: 100 \n",
      "\n",
      "\n",
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n",
      "Accuracy: 0.5597765363128492\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.56      0.93      0.70       995\n",
      "         1.0       0.52      0.10      0.17       795\n",
      "\n",
      "    accuracy                           0.56      1790\n",
      "   macro avg       0.54      0.51      0.43      1790\n",
      "weighted avg       0.55      0.56      0.46      1790\n",
      "\n",
      "\n",
      "Best Parameters:\n",
      " {'alpha': 0.1, 'max_iter': 3695, 'penalty': 'elasticnet', 'tol': 0.001}\n"
     ]
    }
   ],
   "source": [
    "model_data(df=df2, target='condition2', model = SGDClassifier(), param_dist= param_grid_sgd,n_iter=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3470d01a-753d-49d9-9c7e-c3246615b192",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************************************************\n",
      "Running the model task with the following parameters:\n",
      "target: condition2\n",
      "model: KNeighborsClassifier()\n",
      "n_neighbors: [23 22  8  6 14 27 13 16 11 12 27 10 11 18  3 19 11 22  7  5 12  4 25 26\n",
      " 11 12 18 14 25 17  3  9 15 25  7  8 18 15 11 27 12 11 22  3 13  5 14 23\n",
      "  6  7  7 23 11 14 24 12 18 23 18 29 10  9  9 16 22 26 25  4 16  3  6 28\n",
      "  9 15  5  5 24 14 13 18 10 29  9 19 12 14 28 27 17 13 11 12 11  5  6 13\n",
      " 12 24  8 16]\n",
      "weights: ['uniform', 'distance']\n",
      "algorithm: ['ball_tree', 'kd_tree', 'brute']\n",
      "n_class: 2\n",
      "n_iter: 100 \n",
      "\n",
      "\n",
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n",
      "Accuracy: 0.5536312849162012\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.58      0.68      0.63       995\n",
      "         1.0       0.50      0.39      0.44       795\n",
      "\n",
      "    accuracy                           0.55      1790\n",
      "   macro avg       0.54      0.54      0.53      1790\n",
      "weighted avg       0.55      0.55      0.54      1790\n",
      "\n",
      "\n",
      "Best Parameters:\n",
      " {'algorithm': 'ball_tree', 'n_neighbors': 26, 'weights': 'uniform'}\n"
     ]
    }
   ],
   "source": [
    "model_data(df=df2, target='condition2', model = KNeighborsClassifier(), param_dist= param_grid_knn,n_iter=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6b12d6-b0e9-49fb-955d-0998724b711d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************************************************\n",
      "Running the model task with the following parameters:\n",
      "target: condition2\n",
      "model: GaussianNB()\n",
      "n_class: 2\n",
      "n_iter: 100 \n",
      "\n",
      "\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Accuracy: 0.4480446927374302\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.77      0.01      0.02       995\n",
      "         1.0       0.45      1.00      0.62       795\n",
      "\n",
      "    accuracy                           0.45      1790\n",
      "   macro avg       0.61      0.50      0.32      1790\n",
      "weighted avg       0.63      0.45      0.28      1790\n",
      "\n",
      "\n",
      "Best Parameters:\n",
      " {}\n"
     ]
    }
   ],
   "source": [
    "model_data(df=df2, target='condition2', model = GaussianNB(), param_dist= param_grid_nb,n_iter=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44fb9a6-667b-4470-940a-6afb4d343940",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-cpu.2-11.m117",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/tf2-cpu.2-11:m117"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
